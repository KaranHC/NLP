{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas on generating question-answer pairs over a specific document that can be used to build the Knowledge base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = OpenAiService\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import openai\n",
    "# from Utilities.envVars import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key = OpenAiKey\n",
    "# davincimodel= OpenAiDavinci\n",
    "# davincimodel2= OpenAiDavinci2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.0.177"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    PDFMinerLoader,\n",
    "    UnstructuredFileLoader,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import QAGenerationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT35Turbo'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenAiChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0.3\n",
    "tokenLength = 1000\n",
    "\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_key = OpenAiKey\n",
    "        openai.api_version = OpenAiVersion\n",
    "        openai.api_base = openAiEndPoint#f\"https://{OpenAiService}.openai.azure.com\"\n",
    "\n",
    "        llm = AzureChatOpenAI(\n",
    "                openai_api_base=openai.api_base,\n",
    "                openai_api_version=OpenAiVersion,\n",
    "                deployment_name=OpenAiDavinci,\n",
    "                temperature=temperature,\n",
    "                openai_api_key=OpenAiKey,\n",
    "                openai_api_type=\"azure\",\n",
    "                max_tokens=tokenLength,\n",
    "                model_name=OpenAiDavinci)\n",
    "        embeddings = OpenAIEmbeddings(deployment=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "        logging.info(\"LLM Setup done\")\n",
    "# elif embeddingModelType == \"openai\":\n",
    "#         openai.api_type = \"open_ai\"\n",
    "#         openai.api_base = \"https://api.openai.com/v1\"\n",
    "#         openai.api_version = '2020-11-07' \n",
    "#         openai.api_key = OpenAiApiKey\n",
    "#         llm = ChatOpenAI(temperature=temperature,\n",
    "#         openai_api_key=OpenAiApiKey,\n",
    "#         model_name=\"gpt-3.5-turbo\",\n",
    "#         max_tokens=tokenLength)\n",
    "#         embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='Davinci003', temperature=0.3, model_kwargs={}, openai_api_key='555d51f88e9e471b9f417da8b3a42dd6', openai_api_base='https://gpt3tests.openai.azure.com/', openai_organization='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=1000, deployment_name='Davinci003', openai_api_type='azure', openai_api_version='2022-12-01')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT35Turbo'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpenAiChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AzureChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='Davinci003', temperature=0.3, model_kwargs={}, openai_api_key='555d51f88e9e471b9f417da8b3a42dd6', openai_api_base='https://gpt3tests.openai.azure.com/', openai_organization='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=1000, deployment_name='Davinci003', openai_api_type='azure', openai_api_version='2022-12-01'),\n",
       " 'GPT35Turbo')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm,OpenAiChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file name and the namespace for the index\n",
    "fileName = \"Fabric Get Started.pdf\"\n",
    "fabricGetStartedPath = \"Data/PDF/\" + fileName\n",
    "# Load the PDF with Document Loader available from Langchain\n",
    "loader = PDFMinerLoader(fabricGetStartedPath)\n",
    "rawDocs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rawDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell us about your PDF experience.\n",
      "\n",
      "Microsoft Fabric get started\n",
      "documentation\n",
      "\n",
      "Microsoft Fabric is a unified platform that can meet your organization's data and\n",
      "analytics needs. Discover the Fabric shared and platform documentation from this page.\n",
      "\n",
      "About Microsoft Fabric\n",
      "\n",
      "ｅ OVERVIEW\n",
      "\n",
      "What is Fabric?\n",
      "\n",
      "Fabric terminology\n",
      "\n",
      "ｂ GET STARTED\n",
      "\n",
      "Start a Fabric trial\n",
      "\n",
      "Fabric home navigation\n",
      "\n",
      "End-to-end tutorials\n",
      "\n",
      "Context sensitive Help pane\n",
      "\n",
      "Get started with Fabric items\n",
      "\n",
      "ｐ CONCEPT\n",
      "\n",
      "Find items in OneLake data hub\n",
      "\n",
      "Promote and certify items\n",
      "\n",
      "ｃ HOW-TO GUIDE\n",
      "\n",
      "Apply sensitivity labels\n",
      "\n",
      "Workspaces\n",
      "\n",
      "ｐ CONCEPT\n",
      "\n",
      "Fabric workspace\n",
      "\n",
      "\fWorkspace roles\n",
      "\n",
      "ｂ GET STARTED\n",
      "\n",
      "Create a workspace\n",
      "\n",
      "ｃ HOW-TO GUIDE\n",
      "\n",
      "Workspace access control\n",
      "\n",
      "\fWhat is Microsoft Fabric?\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything\n",
      "\n",
      "from data movement to data science, Real-Time Analytics, and business intelligence. It\n",
      "\n",
      "offers a comprehensive suite of services, including data lake, data engineering, and data\n",
      "\n",
      "integration, all in one place.\n",
      "\n",
      "With Fabric, you don't need to piece together different services from multiple vendors.\n",
      "\n",
      "Instead, you can enjoy a highly integrated, end-to-end, and easy-to-use product that is\n",
      "\n",
      "designed to simplify your analytics needs.\n",
      "\n",
      "The platform is built on a foundation of Software as a Service (SaaS), which takes\n",
      "\n",
      "simplicity and integration to a whole new level.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "SaaS foundation\n",
      "\n",
      "Microsoft Fabric brings together new and existing components from Power BI, Azure\n",
      "\n",
      "Synapse, and Azure Data Explorer into a single integrated environment. These\n",
      "\n",
      "components are then presented in various customized user experiences.\n",
      "\n",
      "Fabric brings together experiences such as Data Engineering, Data Factory, Data Science,\n",
      "\n",
      "Data Warehouse, Real-Time Analytics, and Power BI onto a shared SaaS foundation. This\n",
      "\n",
      "integration provides the following advantages:\n",
      "\n",
      "\fAn extensive range of deeply integrated analytics in the industry.\n",
      "\n",
      "Shared experiences across experiences that are familiar and easy to learn.\n",
      "\n",
      "Developers can easily access and reuse all assets.\n",
      "\n",
      "A unified data lake that allows you to retain the data where it is while using your\n",
      "\n",
      "preferred analytics tools.\n",
      "\n",
      "Centralized administration and governance across all experiences.\n",
      "\n",
      "With the Microsoft Fabric SaaS experience, all the data and the services are seamlessly\n",
      "\n",
      "integrated. IT teams can centrally configure core enterprise capabilities and permissions\n",
      "\n",
      "are automatically applied across all the underlying services. Additionally, data sensitivity\n",
      "\n",
      "labels are inherited automatically across the items in the suite.\n",
      "\n",
      "Fabric allows creators to concentrate on producing their best work, freeing them from\n",
      "\n",
      "the need to integrate, manage, or understand the underlying infrastructure that\n",
      "\n",
      "supports the experience.\n",
      "\n",
      "Components of Microsoft Fabric\n",
      "\n",
      "Microsoft Fabric offers the comprehensive set of analytics experiences designed to work\n",
      "\n",
      "together seamlessly. Each experience is tailored to a specific persona and a specific task.\n",
      "\n",
      "Fabric includes industry-leading experiences in the following categories for an end-to-\n",
      "\n",
      "end analytical need.\n",
      "\n",
      "Data Engineering - Data Engineering experience provides a world class Spark\n",
      "\n",
      "platform with great authoring experiences, enabling data engineers to perform\n",
      "\n",
      "large scale data transformation and democratize data through the lakehouse.\n",
      "\n",
      "Microsoft Fabric Spark's integration with Data Factory enables notebooks and\n",
      "\n",
      "spark jobs to be scheduled and orchestrated. For more information, see What is\n",
      "\n",
      "Data engineering in Microsoft Fabric?\n",
      "\n",
      "\fData Factory - Azure Data Factory combines the simplicity of Power Query with the\n",
      "\n",
      "scale and power of Azure Data Factory. You can use more than 200 native\n",
      "\n",
      "connectors to connect to data sources on-premises and in the cloud. For more\n",
      "\n",
      "information, see What is Data Factory in Microsoft Fabric?\n",
      "\n",
      "Data Science - Data Science experience enables you to build, deploy, and\n",
      "\n",
      "operationalize machine learning models seamlessly within your Fabric experience.\n",
      "\n",
      "It integrates with Azure Machine Learning to provide built-in experiment tracking\n",
      "\n",
      "and model registry. Data scientists are empowered to enrich organizational data\n",
      "\n",
      "with predictions and allow business analysts to integrate those predictions into\n",
      "\n",
      "their BI reports. This way it shifts from descriptive to predictive insights. For more\n",
      "\n",
      "information, see What is Data science in Microsoft Fabric?\n",
      "\n",
      "Data Warehouse - Data Warehouse experience provides industry leading SQL\n",
      "\n",
      "performance and scale. It fully separates compute from storage, enabling\n",
      "\n",
      "independent scaling of both the components. Additionally, it natively stores data\n",
      "\n",
      "in the open Delta Lake format. For more information, see What is data\n",
      "\n",
      "warehousing in Microsoft Fabric?\n",
      "\n",
      "Real-Time Analytics - Observational data, which is collected from various sources\n",
      "\n",
      "such as apps, IoT devices, human interactions, and so many more. It's currently the\n",
      "\n",
      "fastest growing data category. This data is often semi-structured in formats like\n",
      "\n",
      "JSON or Text. It comes in at high volume, with shifting schemas. These\n",
      "\n",
      "characteristics make it hard for traditional data warehousing platforms to work\n",
      "\n",
      "with. Real-Time Analytics is best in class engine for observational data analytics.\n",
      "\n",
      "For more information, see What is Real-Time Analytics in Fabric?\n",
      "\n",
      "Power BI - Power BI is the world's leading Business Intelligence platform. It ensures\n",
      "\n",
      "that business owners can access all the data in Fabric quickly and intuitively to\n",
      "\n",
      "make better decisions with data. For more information, see What is Power BI?\n",
      "\n",
      "Fabric brings together all these experiences into a unified platform to offer the most\n",
      "\n",
      "comprehensive big data analytics platform in the industry.\n",
      "\n",
      "Microsoft Fabric enables organizations, and individuals, to turn large and complex data\n",
      "\n",
      "repositories into actionable workloads and analytics, and is an implementation of data\n",
      "\n",
      "mesh architecture. To learn more about data mesh, visit the article that explains data\n",
      "\n",
      "mesh architecture.\n",
      "\n",
      "OneLake and lakehouse - the unification of\n",
      "lakehouses\n",
      "\n",
      "\fThe Microsoft Fabric platform unifies the OneLake and lakehouse architecture across the\n",
      "\n",
      "enterprises.\n",
      "\n",
      "OneLake\n",
      "\n",
      "The data lake is the foundation on which all the Fabric services are built. Microsoft Fabric\n",
      "\n",
      "Lake is also known as OneLake. It's built into the Fabric service and provides a unified\n",
      "\n",
      "location to store all organizational data where the experiences operate.\n",
      "\n",
      "OneLake is built on top of ADLS (Azure Data Lake Storage) Gen2. It provides a single\n",
      "\n",
      "SaaS experience and a tenant-wide store for data that serves both professional and\n",
      "\n",
      "citizen developers. The OneLake SaaS experience simplifies the experiences, eliminating\n",
      "\n",
      "the need for users to understand any infrastructure concepts such as resource groups,\n",
      "\n",
      "RBAC (Role-Based Access Control), Azure Resource Manager, redundancy, or regions.\n",
      "\n",
      "Additionally it doesn't require the user to even have an Azure account.\n",
      "\n",
      "OneLake eliminates today's pervasive and chaotic data silos, which individual developers\n",
      "\n",
      "create when they provision and configure their own isolated storage accounts. Instead,\n",
      "\n",
      "OneLake provides a single, unified storage system for all developers, where discovery\n",
      "\n",
      "and data sharing is trivial and compliance with policy and security settings are enforced\n",
      "\n",
      "centrally and uniformly. For more information, see What is OneLake?\n",
      "\n",
      "Organizational structure of OneLake and lakehouse\n",
      "\n",
      "OneLake is hierarchical in nature to simplify management across your organization. It's\n",
      "\n",
      "built into Microsoft Fabric and there's no requirement for any up-front provisioning.\n",
      "\n",
      "There's only one OneLake per tenant and it provides a single-pane-of-glass file-system\n",
      "\n",
      "namespace that spans across users, regions and even clouds. The data in OneLake is\n",
      "\n",
      "divided into manageable containers for easy handling.\n",
      "\n",
      "The tenant maps to the root of OneLake and is at the top level of the hierarchy. You can\n",
      "\n",
      "create any number of workspaces within a tenant, which can be thought of as folders.\n",
      "\n",
      "The following image shows the various Fabric items where data is stored. It's an example\n",
      "\n",
      "of how various items within Fabric would store data inside OneLake. As displayed, you\n",
      "\n",
      "can create multiple workspaces within a tenant, create multiple lakehouses within each\n",
      "\n",
      "workspace. A lakehouse is a collection of files, folders, and tables that represents a\n",
      "\n",
      "database over a data lake. To learn more, see What is a lakehouse?.\n",
      "\n",
      "\fEvery developer and business unit in the tenant can instantly create their own\n",
      "\n",
      "workspaces in OneLake. They can ingest data into their own lakehouses, start\n",
      "\n",
      "processing, analyzing, and collaborating on the data, just like OneDrive in Office.\n",
      "\n",
      "All the Microsoft Fabric compute experiences are prewired to OneLake, just like the\n",
      "\n",
      "Office applications are prewired to use the organizational OneDrive. The experiences\n",
      "\n",
      "such as Data Engineering, Data Warehouse, Data Factory, Power BI, and Real-Time\n",
      "\n",
      "Analytics use OneLake as their native store. They don't need any extra configuration.\n",
      "\n",
      "OneLake is designed to allow instant mounting of existing PaaS storage accounts into\n",
      "\n",
      "OneLake with the Shortcut feature. There's no need to migrate or move any of the\n",
      "\n",
      "\fexisting data. Using shortcuts, you can access the data stored in Azure Data Lake\n",
      "\n",
      "Storage.\n",
      "\n",
      "Additionally, shortcuts allow you to easily share data between users and applications\n",
      "\n",
      "without moving or duplicating information. The shortcut capability extends to other\n",
      "\n",
      "storage systems, allowing you to compose and analyze data across clouds with\n",
      "\n",
      "transparent, intelligent caching that reduces egress costs and brings data closer to\n",
      "\n",
      "compute.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Microsoft Fabric terminology\n",
      "\n",
      "Create a workspace\n",
      "\n",
      "Navigate to your items from Microsoft Fabric Home page\n",
      "\n",
      "End-to-end tutorials in Microsoft Fabric\n",
      "\n",
      "\fMicrosoft Fabric (Preview) trial\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "The Microsoft Fabric (Preview) trial includes access to the Fabric product experiences\n",
      "\n",
      "and the resources to create and host Fabric items. The Fabric (Preview) trial lasts until\n",
      "\n",
      "Fabric General Availability (GA), unless canceled. After GA, the Fabric (Preview) trial\n",
      "\n",
      "converts to the GA version and is extended for 60 days.\n",
      "\n",
      "This document helps you understand and start a Fabric (Preview) trial.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Existing Power BI users\n",
      "\n",
      "If you're an existing Power BI user, you can skip to Start the Fabric (Preview) trial.\n",
      "\n",
      "Users who are new to Power BI\n",
      "\n",
      "For public preview, the Fabric (Preview) trial requires a Power BI license. Navigate to\n",
      "\n",
      "https://app.fabric.microsoft.com  to sign up for a Power BI free license. Once you have\n",
      "\n",
      "a Power BI license, you can start the Fabric (Preview) trial.\n",
      "\n",
      "Start the Fabric (Preview) trial\n",
      "\n",
      "Follow these steps to start your Fabric (Preview) trial.\n",
      "\n",
      "1. Open the Fabric homepage  and select the Account manager.\n",
      "\n",
      "\f2. In the Account manager, select Start trial.\n",
      "\n",
      "3. If prompted, agree to the terms and then select Start trial.\n",
      "\n",
      "\f4. Once your trial capacity is ready, you receive a confirmation message. Select Got it\n",
      "\n",
      "to begin working in Fabric.\n",
      "\n",
      "5. Open your Account manager again. Notice that you now have a heading for Trial\n",
      "\n",
      "status. Your Account manager keeps track of the number of days remaining in your\n",
      "\n",
      "\ftrial. You also see the countdown in your Fabric menu bar when you work in a\n",
      "\n",
      "product experience.\n",
      "\n",
      "Congratulations! You now have a Fabric (Preview) trial that includes a Power BI individual\n",
      "\n",
      "trial (if you didn't already have a Power BI paid license) and a Fabric (Preview) trial\n",
      "\n",
      "capacity.\n",
      "\n",
      "Other ways to start a Microsoft Fabric (Preview)\n",
      "trial\n",
      "\n",
      "If your Power BI administrator has enabled the preview of Microsoft Fabric for the\n",
      "\n",
      "tenant, you have another option for enabling a Fabric (Preview) trial. When you try to\n",
      "\n",
      "create a Fabric item in a workspace that you own (such as My Workspace) and that\n",
      "\n",
      "workspace doesn't support Fabric items, you're prompted to start a Fabric (Preview) trial.\n",
      "\n",
      "If you agree, your Fabric (Preview) trial starts and your workspace is upgraded to a trial\n",
      "\n",
      "capacity workspace.\n",
      "\n",
      "\fWhat is a trial capacity?\n",
      "\n",
      "A trial capacity is a distinct pool of resources allocated to Microsoft Fabric. The size of\n",
      "\n",
      "the capacity determines the amount of computation power reserved for users of that\n",
      "\n",
      "capacity. The amount of compute resources is based on the SKU.\n",
      "\n",
      "With a Fabric (Preview) trial, you get full access to all of the Fabric experiences and\n",
      "\n",
      "features. You also get OneLake storage up to 1 TB. Create Fabric items and collaborate\n",
      "\n",
      "with others in the same Fabric trial capacity. With a Fabric (Preview) trial, you can:\n",
      "\n",
      "create workspaces (folders) for projects that support Fabric capabilities.\n",
      "\n",
      "share Fabric items, such as datasets, warehouses, and notebooks, and collaborate\n",
      "\n",
      "on them with other Fabric users.\n",
      "\n",
      "create analytics solutions using these Fabric items.\n",
      "\n",
      "You don't have access to your capacity until you put something into it. To begin using\n",
      "\n",
      "your Fabric (Preview) trial, add items to My workspace or create a new workspace.\n",
      "\n",
      "Assign that workspace to your trial capacity using the \"Trial\" license mode, and then all\n",
      "\n",
      "the items in that workspace will be saved and executed in that capacity.\n",
      "\n",
      "To learn more about workspaces and license mode settings, see Workspaces.\n",
      "\n",
      "\fCapacity units\n",
      "\n",
      "When you start a Fabric (Preview) trial, Microsoft provisions one 64 capacity unit (CU)\n",
      "\n",
      "trial capacity. These CUs allow users of your trial capacity to consume 64x60 CU seconds\n",
      "\n",
      "every minute. Every time the Fabric trial capacity is used, it consumes CUs. The Fabric\n",
      "\n",
      "platform aggregates consumption from all experiences and applies it to your reserved\n",
      "\n",
      "capacity. Not all functions have the same consumption rate. For example, running a Data\n",
      "\n",
      "Warehouse might consume more capacity units than authoring a Power BI report. When\n",
      "\n",
      "the capacity consumption exceeds its size, Microsoft slows down the experience similar\n",
      "\n",
      "to slowing down CPU performance.\n",
      "\n",
      "There's no limit on the number of workspaces or items you can create within your\n",
      "\n",
      "capacity. The only constraint is the availability of capacity units and the rate at which you\n",
      "\n",
      "consume them.\n",
      "\n",
      "You're the capacity owner for your trial capacity. As your own capacity administrator for\n",
      "\n",
      "your Fabric trial capacity, you have access to a detailed and transparent report for how\n",
      "\n",
      "capacity units are consumed via the Capacity Metrics app. For more information about\n",
      "\n",
      "administering your trials, see Administer a Fabric trial capacity.\n",
      "\n",
      "End a Fabric (Preview) trial\n",
      "\n",
      "\fYou may cancel your trial from the Account manager. When you cancel your free Fabric\n",
      "\n",
      "(Preview) trial, the trial capacity, with all of its workspaces and their contents, is deleted.\n",
      "\n",
      "In addition, you can't:\n",
      "\n",
      "create workspaces that support Fabric capabilities.\n",
      "\n",
      "share Fabric items, such as machine learning models, warehouses, and notebooks,\n",
      "\n",
      "and collaborate on them with other Fabric users.\n",
      "\n",
      "create analytics solutions using these Fabric items.\n",
      "\n",
      "Additionally, if you cancel your trial, you may not be able to start another trial.\n",
      "\n",
      "Administer user access to a Fabric (Preview)\n",
      "trial\n",
      "\n",
      "Power BI administrators can enable and disable trials for paid features for Power BI and\n",
      "\n",
      "Fabric. This setting is at a tenant level and is applied to all users or to specific security\n",
      "\n",
      "groups. This one tenant setting applies to both Power BI and Fabric trials, so Power BI\n",
      "\n",
      "administrators should carefully evaluate the impact of making a change to this setting.\n",
      "\n",
      "Each trial user is the capacity admin for their trial capacity. Microsoft currently doesn't\n",
      "\n",
      "support multiple capacity administrators per trial capacity. Therefore, Power BI\n",
      "\n",
      "administrators can't view metrics for individual capacities. We do have plans to support\n",
      "\n",
      "this capability in an upcoming admin monitoring feature.\n",
      "\n",
      "\fConsiderations and limitations\n",
      "\n",
      "I am unable to start a trial\n",
      "\n",
      "If you don't see the Start trial button in your Account manager:\n",
      "\n",
      "Your Power BI administrator may have disabled access, and you can't start a Fabric\n",
      "\n",
      "(Preview) trial. Contact your Power BI administrator to request access. You can also\n",
      "\n",
      "start a trial using your own tenant. For more information, see Sign up for Power BI\n",
      "\n",
      "with a new Microsoft 365 account.\n",
      "\n",
      "If you're an existing Power BI trial user, you don't see Start trial in your Account\n",
      "\n",
      "manager. You can start a Fabric (Preview) trial by attempting to create a Fabric\n",
      "\n",
      "item. When you attempt to create a Fabric item, you're prompted to start a Fabric\n",
      "\n",
      "(Preview) trial. If you don't see this prompt, your Power BI administrator may have\n",
      "\n",
      "disabled the Fabric (Preview) feature.\n",
      "\n",
      "If you do see the Start trial button in your Account manager:\n",
      "\n",
      "you might not be able to start a trial if your tenant has exhausted its limit of trial\n",
      "\n",
      "capacities. If that is the case, you have the following options:\n",
      "\n",
      "Purchase a Fabric capacity from Azure\n",
      "\n",
      "Request another trial capacity user to share their trial capacity with you.\n",
      "\n",
      "Reach out to your Power BI administrator to create a CSS request to increase\n",
      "\n",
      "tenant trial capacity limits.\n",
      "\n",
      "In Workplace settings, I can't assign a workspace to the trial capacity\n",
      "\n",
      "This known bug occurs when the Power BI administrator turns off trials after you start a\n",
      "\n",
      "trial. To add your workspace to the trial capacity, open the Admin portal by selecting it\n",
      "\n",
      "from the gear icon in the top menu bar. Then, select Trial > Capacity settings and\n",
      "\n",
      "choose the name of the capacity. If you don't see your workspace assigned, add it here.\n",
      "\n",
      "\fWhat is the region for my Fabric (Preview) trial capacity?\n",
      "\n",
      "If you start the trial using the Account manager, your trial capacity is located in the\n",
      "\n",
      "home region for your tenant. To identify the home region, select the ? icon on the top\n",
      "\n",
      "menu bar and then choose About Power BI > About Fabric. Your home region is where\n",
      "\n",
      "your data is stored.\n",
      "\n",
      "What impact does region have on my Fabric (Preview) trial? If your home region\n",
      "\n",
      "doesn't have Fabric enabled, you won't be able to create any Fabric items in your trial\n",
      "\n",
      "capacity. When Fabric is Generally Available (GA), you can use the Account manager to\n",
      "\n",
      "start a trial and assign your Fabric capacity to a specific region. Until GA, if your home\n",
      "\n",
      "region doesn't have Fabric enabled, don't use the Account manager to start a trial. If\n",
      "\n",
      "you've already started a trial from Account manager, cancel that trial and follow the\n",
      "\n",
      "steps in Other ways to start a Fabric (Preview) trial instead.\n",
      "\n",
      "How is the Fabric (Preview) trial different from an individual trial of Power BI paid?\n",
      "\n",
      "A per-user trial of Power BI paid allows access to the Fabric landing page. Once you sign\n",
      "\n",
      "up for the Fabric (Preview) trial, you can use the trial capacity for storing Fabric\n",
      "\n",
      "workspaces and items and for running Fabric experiences. All rules guiding Power BI\n",
      "\n",
      "licenses and what you can do in the Power BI experience remain the same. The key\n",
      "\n",
      "difference is that a Fabric capacity is required to access non-Power BI experiences and\n",
      "\n",
      "items.\n",
      "\n",
      "Private links and private access\n",
      "\n",
      "During the Fabric preview, you can't create Fabric items in the trial capacity if you or\n",
      "\n",
      "your tenant have private links enabled and public access is disabled. This limitation is a\n",
      "\n",
      "known bug for Fabric preview.\n",
      "\n",
      "Autoscale\n",
      "\n",
      "\fThe Fabric (Preview) trial capacity doesn't support autoscale. If you need more compute\n",
      "\n",
      "capacity, you can purchase a Fabric capacity in Azure.\n",
      "\n",
      "For existing Synapse users\n",
      "\n",
      "The Fabric (Preview) trial is different from a Proof of Concept (POC). A Proof of\n",
      "\n",
      "Concept (POC) is standard enterprise vetting that requires financial investment and\n",
      "\n",
      "months' worth of work customizing the platform and using fed data. The Fabric\n",
      "\n",
      "(Preview) trial is free for users through public preview and doesn't require\n",
      "\n",
      "customization. Users can sign up for a free trial and start running product\n",
      "\n",
      "experiences immediately, within the confines of available capacity units.\n",
      "\n",
      "You don't need an Azure subscription to start a Fabric (Preview) trial. If you have an\n",
      "\n",
      "existing Azure subscription, you can purchase a (paid) Fabric capacity.\n",
      "\n",
      "For existing Power BI users\n",
      "\n",
      "You can migrate your existing workspaces into a trial capacity using workspace settings\n",
      "\n",
      "and choosing \"Trial\" as the license mode. To learn how to migrate workspaces, see\n",
      "\n",
      "create workspaces.\n",
      "\n",
      "\fNext steps\n",
      "\n",
      "Learn about licenses\n",
      "\n",
      "Review Fabric terminology\n",
      "\n",
      "\fMicrosoft Fabric terminology\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Learn the definitions of terms used in Microsoft Fabric, including terms specific to\n",
      "\n",
      "Synapse Data Warehouse, Synapse Data Engineering, Synapse Data Science, Synapse\n",
      "\n",
      "Real-Time Analytics, Data Factory, and Power BI.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "General terms\n",
      "\n",
      "Capacity: Capacity is a dedicated set of resources that is available at a given time\n",
      "\n",
      "to be used. Capacity defines the ability of a resource to perform an activity or to\n",
      "\n",
      "produce output. Different items consume different capacity at a certain time. Fabric\n",
      "\n",
      "offers capacity through the Fabric SKU and Trials. For more information, see What\n",
      "\n",
      "is capacity?\n",
      "\n",
      "Experience: A collection of capabilities targeted to a specific functionality. The\n",
      "\n",
      "Fabric experiences include Synapse Data Warehouse, Synapse Data Engineering,\n",
      "\n",
      "Synapse Data Science, Synapse Real-Time Analytics, Data Factory and Power BI.\n",
      "\n",
      "Item: An item a set of capabilities within an experience. Users can create, edit, and\n",
      "\n",
      "delete them. Each item type provides different capabilities. For example, the Data\n",
      "\n",
      "Engineering experience includes the lakehouse, notebook, and Spark job definition\n",
      "\n",
      "items.\n",
      "\n",
      "Tenant: A tenant is a single instance of Fabric for an organization and is aligned\n",
      "\n",
      "with an Azure Active Directory.\n",
      "\n",
      "Workspace: A workspace is a collection of items that brings together different\n",
      "\n",
      "functionality in a single environment designed for collaboration. It acts as a\n",
      "\n",
      "container that leverages capacity for the work that is executed, and provides\n",
      "\n",
      "controls for who can access the items in it. For example, in a workspace, users\n",
      "\n",
      "create reports, notebooks, datasets, etc. For more information, see Workspaces\n",
      "\n",
      "article.\n",
      "\n",
      "\fSynapse Data Engineering\n",
      "\n",
      "Lakehouse: A lakehouse is a collection of files, folders, and tables that represent a\n",
      "\n",
      "database over a data lake used by the Apache Spark engine and SQL engine for\n",
      "\n",
      "big data processing. A lakehouse includes enhanced capabilities for ACID\n",
      "\n",
      "transactions when using the open-source Delta formatted tables. The lakehouse\n",
      "\n",
      "item is hosted within a unique workspace folder in Microsoft OneLake. It contains\n",
      "\n",
      "files in various formats (structured and unstructured) organized in folders and\n",
      "\n",
      "subfolders. For more information, see What is a lakehouse?\n",
      "\n",
      "Notebook: A Fabric notebook is a multi-language interactive programming tool\n",
      "\n",
      "with rich functions. Which include authoring code and markdown, running and\n",
      "\n",
      "monitoring a Spark job, viewing and visualizing result, and collaborating with the\n",
      "\n",
      "team. It helps data engineers and data scientist to explore and process data, and\n",
      "\n",
      "build machine learning experiments with both code and low-code experience. It\n",
      "\n",
      "can be easily transformed to a pipeline activity for orchestration.\n",
      "\n",
      "Spark application: An Apache Spark application is a program written by a user\n",
      "\n",
      "using one of Spark's API languages (Scala, Python, Spark SQL, or Java) or\n",
      "\n",
      "Microsoft-added languages (.NET with C# or F#). When an application runs, it's\n",
      "\n",
      "divided into one or more Spark jobs that run in parallel to process the data faster.\n",
      "\n",
      "For more information, see Spark application monitoring.\n",
      "\n",
      "Apache Spark job: A Spark job is part of a Spark application that is run in parallel\n",
      "\n",
      "with other jobs in the application. A job consists of multiple tasks. For more\n",
      "\n",
      "information, see Spark job monitoring.\n",
      "\n",
      "Apache Spark job definition: A Spark job definition is a set of parameters, set by\n",
      "\n",
      "the user, indicating how a Spark application should be run. It allows you to submit\n",
      "\n",
      "batch or streaming jobs to the Spark cluster. For more information, see What is an\n",
      "\n",
      "Apache Spark job definition?\n",
      "\n",
      "V-order: A write optimization to the parquet file format that enables fast reads and\n",
      "\n",
      "provides cost efficiency and better performance. All the Fabric engines write v-\n",
      "\n",
      "ordered parquet files by default.\n",
      "\n",
      "Data Factory\n",
      "\n",
      "Connector: Data Factory offers a rich set of connectors that allow you to connect\n",
      "\n",
      "to different types of data stores. Once connected, you can transform the data. For\n",
      "\n",
      "more information, see connectors.\n",
      "\n",
      "\fData pipeline: In Data Factory, a data pipeline is used for orchestrating data\n",
      "\n",
      "movement and transformation. These pipelines are different from the deployment\n",
      "\n",
      "pipelines in Fabric. For more information, see Pipelines in the Data Factory\n",
      "\n",
      "overview.\n",
      "\n",
      "Dataflow Gen2: Dataflows provide a low-code interface for ingesting data from\n",
      "\n",
      "hundreds of data sources and transforming your data. Dataflows in Fabric are\n",
      "\n",
      "referred to as Dataflow Gen2. Dataflow Gen1 exists in Power BI. Dataflow Gen2\n",
      "\n",
      "offers extra capabilities compared to Dataflows in Azure Data Factory or Power BI.\n",
      "\n",
      "You can't upgrade from Gen1 to Gen2. For more information, see Dataflows in the\n",
      "\n",
      "Data Factory overview.\n",
      "\n",
      "Synapse Data Science\n",
      "\n",
      "Data Wrangler: Data Wrangler is a notebook-based tool that provides users with\n",
      "\n",
      "an immersive experience to conduct exploratory data analysis. The feature\n",
      "\n",
      "combines a grid-like data display with dynamic summary statistics and a set of\n",
      "\n",
      "common data-cleansing operations, all available with a few selected icons. Each\n",
      "\n",
      "operation generates code that can be saved back to the notebook as a reusable\n",
      "\n",
      "script.\n",
      "\n",
      "Experiment: A machine learning experiment is the primary unit of organization and\n",
      "\n",
      "control for all related machine learning runs. For more information, see Machine\n",
      "\n",
      "learning experiments in Microsoft Fabric.\n",
      "\n",
      "Model: A machine learning model is a file trained to recognize certain types of\n",
      "\n",
      "patterns. You train a model over a set of data, and you provide it with an algorithm\n",
      "\n",
      "that it uses to reason over and learn from that data set. For more information, see\n",
      "\n",
      "Machine learning model.\n",
      "\n",
      "Run: A run corresponds to a single execution of model code. In MLflow , tracking\n",
      "\n",
      "is based on experiments and runs.\n",
      "\n",
      "Synapse data warehousing\n",
      "\n",
      "SQL Endpoint: Each Lakehouse has a SQL Endpoint that allows a user to query\n",
      "\n",
      "delta table data with TSQL over TDS. For more information, see SQL Endpoint.\n",
      "\n",
      "Synapse Data Warehouse: The Synapse Data Warehouse functionality is a\n",
      "\n",
      "traditional data warehouse and supports the full transactional T-SQL capabilities\n",
      "\n",
      "you would expect from an enterprise data warehouse. For more information, see\n",
      "\n",
      "Synapse Data Warehouse.\n",
      "\n",
      "\fSynapse Real-Time Analytics\n",
      "\n",
      "KQL database: The KQL database is the representation of a database holding data\n",
      "\n",
      "in a format to execute a KQL query against it. For more information, see Query a\n",
      "\n",
      "KQL database.\n",
      "\n",
      "KQL Queryset: The KQL Queryset is the item used to run queries, view results, and\n",
      "\n",
      "manipulate query results on data from your Data Explorer database. The queryset\n",
      "\n",
      "includes the databases and tables, the queries, and the results. The KQL Queryset\n",
      "\n",
      "allows you to save queries for future use, or export and share queries with others.\n",
      "\n",
      "For more information, see Query data in the KQL Queryset\n",
      "\n",
      "Event stream: The Microsoft Fabric event streams feature provides a centralized\n",
      "\n",
      "place in the Fabric platform to capture, transform, and route real-time events to\n",
      "\n",
      "destinations with a no-code experience. An event stream consists of various\n",
      "\n",
      "streaming data sources, ingestion destinations, and an event processor when the\n",
      "\n",
      "transformation is needed. For more information, see Microsoft Fabric event\n",
      "\n",
      "streams.\n",
      "\n",
      "OneLake\n",
      "\n",
      "Shortcut: Shortcuts are embedded references within OneLake that point to other\n",
      "\n",
      "file store locations. They provide a way to connect to existing data without having\n",
      "\n",
      "to directly copy it. For more information, see OneLake shortcuts.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Navigate to your items from Microsoft Fabric Home page\n",
      "\n",
      "Discover data items in the OneLake data hub\n",
      "\n",
      "End-to-end tutorials in Microsoft Fabric\n",
      "\n",
      "\fEnd-to-end tutorials in Microsoft Fabric\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "In this article, you find a comprehensive list of end-to-end tutorials available in\n",
      "\n",
      "Microsoft Fabric. These tutorials guide you through a scenario that covers the entire\n",
      "\n",
      "process, from data acquisition to data consumption. They're designed to help you\n",
      "\n",
      "develop a foundational understanding of the Fabric UI, the various experiences\n",
      "\n",
      "supported by Fabric and their integration points, and the professional and citizen\n",
      "\n",
      "developer experiences that are available.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Multi-experience tutorials\n",
      "\n",
      "The following table lists tutorials that span multiple Fabric experiences.\n",
      "\n",
      "Tutorial\n",
      "name\n",
      "\n",
      "Lakehouse\n",
      "\n",
      "Scenario\n",
      "\n",
      "In this tutorial, you ingest, transform, and load the data of a fictional retail company,\n",
      "Wide World Importers, into the lakehouse and analyze sales data across various\n",
      "dimensions.\n",
      "\n",
      "Data\n",
      "Science\n",
      "\n",
      "In this tutorial, you explore, clean, and transform a taxicab trip dataset, and build a\n",
      "machine learning model to predict trip duration at scale on a large dataset.\n",
      "\n",
      "Real-Time\n",
      "Analytics\n",
      "\n",
      "In this tutorial, you use the streaming and query capabilities of Real-Time Analytics\n",
      "to analyze the New York Yellow Taxi trip dataset. You uncover essential insights into\n",
      "trip statistics, taxi demand across the boroughs of New York, and other related\n",
      "\n",
      "insights.\n",
      "\n",
      "Data\n",
      "\n",
      "In this tutorial, you build an end-to-end data warehouse for the fictional Wide World\n",
      "\n",
      "warehouse\n",
      "\n",
      "Importers company. You ingest data into data warehouse, transform it using T-SQL\n",
      "and pipelines, run queries, and build reports.\n",
      "\n",
      "Experience-specific tutorials\n",
      "\n",
      "The following tutorials walk you through scenarios within specific Fabric experiences.\n",
      "\n",
      "\fTutorial name\n",
      "\n",
      "Scenario\n",
      "\n",
      "Power BI\n",
      "\n",
      "In this tutorial, you build a dataflow and pipeline to bring data into a lakehouse,\n",
      "create a dimensional model, and generate a compelling report.\n",
      "\n",
      "Data Factory\n",
      "\n",
      "In this tutorial, you ingest data with data pipelines and transform data with\n",
      "dataflows, then use the automation and notification to create a complete data\n",
      "integration scenario.\n",
      "\n",
      "Data Science\n",
      "end-to-end AI\n",
      "\n",
      "In this set of tutorials, learn about the different Data Science experience\n",
      "capabilities and examples of how ML models can address your common\n",
      "\n",
      "samples\n",
      "\n",
      "business problems.\n",
      "\n",
      "Data Science -\n",
      "Price prediction\n",
      "with R\n",
      "\n",
      "In this tutorial, you build a machine learning model to analyze and visualize the\n",
      "avocado prices in the US and predict future prices.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Create a workspace\n",
      "\n",
      "Discover data items in the OneLake data hub\n",
      "\n",
      "\fMicrosoft Fabric decision guide: copy\n",
      "activity, dataflow, or Spark\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Use this reference guide and the example scenarios to help you in deciding whether you\n",
      "\n",
      "need a copy activity, a dataflow, or Spark for your workloads using Microsoft Fabric.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Copy activity, dataflow, and Spark properties\n",
      "\n",
      "Use case\n",
      "\n",
      "Primary\n",
      "developer\n",
      "\n",
      "persona\n",
      "\n",
      "Primary\n",
      "developer skill\n",
      "\n",
      "set\n",
      "\n",
      "Code written\n",
      "\n",
      "Pipeline copy activity\n",
      "\n",
      "Data lake and data warehouse\n",
      "migration, \n",
      "data ingestion, \n",
      "lightweight transformation\n",
      "\n",
      "Data engineer, \n",
      "data integrator\n",
      "\n",
      "ETL, \n",
      "SQL, \n",
      "\n",
      "JSON\n",
      "\n",
      "No code, \n",
      "low code\n",
      "\n",
      "Dataflow Gen\n",
      "2\n",
      "\n",
      "Data ingestion, \n",
      "data\n",
      "transformation, \n",
      "data\n",
      "wrangling, \n",
      "data profiling\n",
      "\n",
      "Data engineer, \n",
      "data\n",
      "\n",
      "integrator, \n",
      "business\n",
      "analyst\n",
      "\n",
      "ETL, \n",
      "M, \n",
      "\n",
      "SQL\n",
      "\n",
      "No code, \n",
      "low code\n",
      "\n",
      "Spark\n",
      "\n",
      "Data ingestion, \n",
      "data transformation, \n",
      "data processing, \n",
      "data profiling\n",
      "\n",
      "Data engineer, \n",
      "data scientist, \n",
      "\n",
      "data developer\n",
      "\n",
      "Spark (Scala, Python,\n",
      "Spark SQL, R)\n",
      "\n",
      "Code\n",
      "\n",
      "Data volume\n",
      "\n",
      "Low to high\n",
      "\n",
      "Low to high\n",
      "\n",
      "Low to high\n",
      "\n",
      "Development\n",
      "interface\n",
      "\n",
      "Wizard, \n",
      "canvas\n",
      "\n",
      "Power query\n",
      "\n",
      "Notebook, \n",
      "Spark job definition\n",
      "\n",
      "\fPipeline copy activity\n",
      "\n",
      "Dataflow Gen\n",
      "2\n",
      "\n",
      "Spark\n",
      "\n",
      "Sources\n",
      "\n",
      "30+ connectors\n",
      "\n",
      "150+\n",
      "connectors\n",
      "\n",
      "Hundreds of Spark\n",
      "libraries\n",
      "\n",
      "Destinations\n",
      "\n",
      "18+ connectors\n",
      "\n",
      "Lakehouse, \n",
      "\n",
      "Hundreds of Spark\n",
      "\n",
      "libraries\n",
      "\n",
      "Azure SQL\n",
      "database, \n",
      "\n",
      "Azure Data\n",
      "explorer, \n",
      "Azure Synapse\n",
      "\n",
      "analytics\n",
      "\n",
      "Transformation\n",
      "\n",
      "complexity\n",
      "\n",
      "Low: \n",
      "\n",
      "Low to high: \n",
      "\n",
      "Low to high: \n",
      "\n",
      "lightweight - type conversion,\n",
      "column mapping, merge/split files,\n",
      "\n",
      "300+\n",
      "transformation\n",
      "\n",
      "support for native\n",
      "Spark and open-\n",
      "\n",
      "flatten hierarchy\n",
      "\n",
      "functions\n",
      "\n",
      "source libraries\n",
      "\n",
      "Review the following three scenarios for help with choosing how to work with your data\n",
      "\n",
      "in Fabric.\n",
      "\n",
      "Scenario1\n",
      "\n",
      "Leo, a data engineer, needs to ingest a large volume of data from external systems, both\n",
      "\n",
      "on-premises and cloud. These external systems include databases, file systems, and APIs.\n",
      "\n",
      "Leo doesn’t want to write and maintain code for each connector or data movement\n",
      "\n",
      "operation. He wants to follow the medallion layers best practices, with bronze, silver,\n",
      "\n",
      "and gold. Leo doesn't have any experience with Spark, so he prefers the drag and drop\n",
      "\n",
      "UI as much as possible, with minimal coding. And he also wants to process the data on a\n",
      "\n",
      "schedule.\n",
      "\n",
      "The first step is to get the raw data into the bronze layer lakehouse from Azure data\n",
      "\n",
      "resources and various third party sources (like Snowflake Web, REST, AWS S3, GCS, etc.).\n",
      "\n",
      "He wants a consolidated lakehouse, so that all the data from various LOB, on-premises,\n",
      "\n",
      "and cloud sources reside in a single place. Leo reviews the options and selects pipeline\n",
      "\n",
      "copy activity as the appropriate choice for his raw binary copy. This pattern applies to\n",
      "\n",
      "both historical and incremental data refresh. With copy activity, Leo can load Gold data\n",
      "\n",
      "to a data warehouse with no code if the need arises and pipelines provide high scale\n",
      "\n",
      "data ingestion that can move petabyte-scale data. Copy activity is the best low-code\n",
      "\n",
      "and no-code choice to move petabytes of data to lakehouses and warehouses from\n",
      "\n",
      "varieties of sources, either ad-hoc or via a schedule.\n",
      "\n",
      "\fScenario2\n",
      "\n",
      "Mary is a data engineer with a deep knowledge of the multiple LOB analytic reporting\n",
      "\n",
      "requirements. An upstream team has successfully implemented a solution to migrate\n",
      "\n",
      "multiple LOB's historical and incremental data into a common lakehouse. Mary has been\n",
      "\n",
      "tasked with cleaning the data, applying business logics, and loading it into multiple\n",
      "\n",
      "destinations (such as Azure SQL DB, ADX, and a lakehouse) in preparation for their\n",
      "\n",
      "respective reporting teams.\n",
      "\n",
      "Mary is an experienced Power Query user, and the data volume is in the low to medium\n",
      "\n",
      "range to achieve desired performance. Dataflows provide no-code or low-code\n",
      "\n",
      "interfaces for ingesting data from hundreds of data sources. With dataflows, you can\n",
      "\n",
      "transform data using 300+ data transformation options, and write the results into\n",
      "\n",
      "multiple destinations with an easy to use, highly visual user interface. Mary reviews the\n",
      "\n",
      "options and decides that it makes sense to use Dataflow Gen 2 as her preferred\n",
      "\n",
      "transformation option.\n",
      "\n",
      "Scenario3\n",
      "\n",
      "Adam is a data engineer working for a large retail company that uses a lakehouse to\n",
      "\n",
      "store and analyze its customer data. As part of his job, Adam is responsible for building\n",
      "\n",
      "and maintaining the data pipelines that extract, transform, and load data into the\n",
      "\n",
      "lakehouse. One of the company's business requirements is to perform customer review\n",
      "\n",
      "analytics to gain insights into their customers' experiences and improve their services.\n",
      "\n",
      "Adam decides the best option is to use Spark to build the extract and transformation\n",
      "\n",
      "logic. Spark provides a distributed computing platform that can process large amounts\n",
      "\n",
      "of data in parallel. He writes a Spark application using Python or Scala, which reads\n",
      "\n",
      "structured, semi-structured, and unstructured data from OneLake for customer reviews\n",
      "\n",
      "and feedback. The application cleanses, transforms, and writes data to Delta tables in\n",
      "\n",
      "the lakehouse. The data is then ready to be used for downstream analytics.\n",
      "\n",
      "Next steps\n",
      "\n",
      "How to copy data using copy activity\n",
      "\n",
      "Quickstart: Create your first dataflow to get and transform data\n",
      "\n",
      "How to create an Apache Spark job definition in Fabric\n",
      "\n",
      "\fMicrosoft Fabric decision guide: data\n",
      "warehouse or lakehouse\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Use this reference guide and the example scenarios to help you choose between the\n",
      "\n",
      "data warehouse or a lakehouse for your workloads using Microsoft Fabric.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Data warehouse and lakehouse properties\n",
      "\n",
      "Data warehouse\n",
      "\n",
      "Lakehouse\n",
      "\n",
      "Data volume\n",
      "\n",
      "Unlimited\n",
      "\n",
      "Unlimited\n",
      "\n",
      "Type of data\n",
      "\n",
      "Structured\n",
      "\n",
      "Unstructured, \n",
      "semi-structured, \n",
      "structured\n",
      "\n",
      "Power BI\n",
      "Datamart\n",
      "\n",
      "Up to 100\n",
      "GB\n",
      "\n",
      "Structured\n",
      "\n",
      "Primary\n",
      "developer\n",
      "persona\n",
      "\n",
      "Primary\n",
      "developer skill\n",
      "\n",
      "set\n",
      "\n",
      "Data warehouse developer, \n",
      "SQL engineer\n",
      "\n",
      "Data engineer, \n",
      "data scientist\n",
      "\n",
      "Citizen\n",
      "developer\n",
      "\n",
      "SQL\n",
      "\n",
      "Spark \n",
      "(Scala, PySpark, Spark SQL, R)\n",
      "\n",
      "No code,\n",
      "SQL\n",
      "\n",
      "Data organized\n",
      "\n",
      "Databases, schemas, and\n",
      "\n",
      "Folders and files, \n",
      "\n",
      "Database,\n",
      "\n",
      "by\n",
      "\n",
      "tables\n",
      "\n",
      "databases and tables\n",
      "\n",
      "Read\n",
      "\n",
      "operations\n",
      "\n",
      "Write\n",
      "operations\n",
      "\n",
      "Spark, \n",
      "\n",
      "T-SQL\n",
      "\n",
      "T-SQL\n",
      "\n",
      "Spark, \n",
      "\n",
      "T-SQL\n",
      "\n",
      "tables,\n",
      "queries\n",
      "\n",
      "Spark, \n",
      "\n",
      "T-SQL, \n",
      "Power BI\n",
      "\n",
      "Spark \n",
      "(Scala, PySpark, Spark SQL, R)\n",
      "\n",
      "Dataflows,\n",
      "T-SQL\n",
      "\n",
      "\fMulti-table\n",
      "transactions\n",
      "\n",
      "Primary\n",
      "\n",
      "development\n",
      "interface\n",
      "\n",
      "Security\n",
      "\n",
      "Data warehouse\n",
      "\n",
      "Lakehouse\n",
      "\n",
      "Power BI\n",
      "Datamart\n",
      "\n",
      "Yes\n",
      "\n",
      "No\n",
      "\n",
      "No\n",
      "\n",
      "SQL scripts\n",
      "\n",
      "Spark notebooks, \n",
      "\n",
      "Power BI\n",
      "\n",
      "Spark job definitions\n",
      "\n",
      "Object level (table, view,\n",
      "function, stored procedure,\n",
      "etc.), \n",
      "\n",
      "column level, \n",
      "row level, \n",
      "\n",
      "DDL/DML\n",
      "\n",
      "Row level, \n",
      "table level (when using T-\n",
      "SQL), \n",
      "\n",
      "none for Spark\n",
      "\n",
      "Built-in RLS\n",
      "editor\n",
      "\n",
      "Access data via\n",
      "\n",
      "Yes (indirectly through the\n",
      "\n",
      "Yes\n",
      "\n",
      "shortcuts\n",
      "\n",
      "lakehouse)\n",
      "\n",
      "Can be a source\n",
      "\n",
      "for shortcuts\n",
      "\n",
      "Yes (tables)\n",
      "\n",
      "Yes (files and tables)\n",
      "\n",
      "No\n",
      "\n",
      "No\n",
      "\n",
      "Query across\n",
      "\n",
      "Yes, query across lakehouse\n",
      "\n",
      "Yes, query across lakehouse\n",
      "\n",
      "No\n",
      "\n",
      "items\n",
      "\n",
      "and warehouse tables\n",
      "\n",
      "and warehouse tables; \n",
      "query across lakehouses\n",
      "\n",
      "(including shortcuts using\n",
      "\n",
      "Spark)\n",
      "\n",
      "Scenarios\n",
      "\n",
      "Review these scenarios for help with choosing between using a lakehouse or a data\n",
      "\n",
      "warehouse in Fabric.\n",
      "\n",
      "Scenario 1\n",
      "\n",
      "Susan, a professional developer, is new to Microsoft Fabric. They are ready to get started\n",
      "\n",
      "cleaning, modeling, and analyzing data but need to decide to build a data warehouse or\n",
      "\n",
      "a lakehouse. After review of the details in the previous table, the primary decision points\n",
      "\n",
      "are the available skill set and the need for multi-table transactions.\n",
      "\n",
      "Susan has spent many years building data warehouses on relational database engines,\n",
      "\n",
      "and is familiar with SQL syntax and functionality. Thinking about the larger team, the\n",
      "\n",
      "primary consumers of this data are also skilled with SQL and SQL analytical tools. Susan\n",
      "\n",
      "decides to use a data warehouse, which allows the team to interact primarily with T-\n",
      "\n",
      "SQL, while also allowing any Spark users in the organization to access the data.\n",
      "\n",
      "\fScenario 2\n",
      "\n",
      "Rob, a data engineer, needs to store and model several terabytes of data in Fabric. The\n",
      "\n",
      "team has a mix of PySpark and T-SQL skills. Most of the team running T-SQL queries are\n",
      "\n",
      "consumers, and therefore don't need to write INSERT, UPDATE, or DELETE statements.\n",
      "\n",
      "The remaining developers are comfortable working in notebooks, and because the data\n",
      "\n",
      "is stored in Delta, they're able to interact with a similar SQL syntax.\n",
      "\n",
      "Rob decides to use a lakehouse, which allows the data engineering team to use their\n",
      "\n",
      "diverse skills against the data, while allowing the team members who are highly skilled\n",
      "\n",
      "in T-SQL to consume the data.\n",
      "\n",
      "Scenario 3\n",
      "\n",
      "Ash, a citizen developer, is a Power BI developer. They're familiar with Excel, Power BI,\n",
      "\n",
      "and Office. They need to build a data product for a business unit. They know they don't\n",
      "\n",
      "quite have the skills to build a data warehouse or a lakehouse, and those seem like too\n",
      "\n",
      "much for their needs and data volumes. They review the details in the previous table\n",
      "\n",
      "and see that the primary decision points are their own skills and their need for a self\n",
      "\n",
      "service, no code capability, and data volume under 100 GB.\n",
      "\n",
      "Ash works with business analysts familiar with Power BI and Microsoft Office, and knows\n",
      "\n",
      "that they already have a Premium capacity subscription. As they think about their larger\n",
      "\n",
      "team, they realize the primary consumers of this data may be analysts, familiar with no-\n",
      "\n",
      "code and SQL analytical tools. Ash decides to use a Power BI datamart, which allows the\n",
      "\n",
      "team to interact build the capability fast, using a no-code experience. Queries can be\n",
      "\n",
      "executed via Power BI and T-SQL, while also allowing any Spark users in the organization\n",
      "\n",
      "to access the data as well.\n",
      "\n",
      "Next steps\n",
      "\n",
      "What is data warehousing in Microsoft Fabric?\n",
      "\n",
      "Create a warehouse in Microsoft Fabric\n",
      "\n",
      "Create a lakehouse in Microsoft Fabric\n",
      "\n",
      "Introduction to Power BI datamarts\n",
      "\n",
      "\fNavigate to your items from Microsoft\n",
      "Fabric Home\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "This article gives a high level view of navigating to your items and actions from\n",
      "\n",
      "Microsoft Fabric Home. Each product experience has its own Home, and there are\n",
      "\n",
      "similarities that they all share. Those similarities are described in this article. For detailed\n",
      "\n",
      "information about Home for a particular product experience, such as Data Factory\n",
      "\n",
      "Home, visit the relevant page for that product experience.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Overview of Home\n",
      "\n",
      "On Home, you see items that you create and that you have permission to use. These are\n",
      "\n",
      "items from all the workspaces that you access. That means that the items available on\n",
      "\n",
      "everyone's Home are different. At first, you might not have much content, but that\n",
      "\n",
      "changes as you start to create and share Microsoft Fabric items.\n",
      "\n",
      "７ Note\n",
      "\n",
      "Home is not workspace-specific. For example, the Recent area on Home might\n",
      "\n",
      "include items from many different workspaces.\n",
      "\n",
      "In Microsoft Fabric, the term item refers to: apps, lakehouses, warehouses, reports, and\n",
      "\n",
      "more. Your items are accessible and viewable in Microsoft Fabric, and often the best\n",
      "\n",
      "place to start working in Microsoft Fabric is from Home. However, once you've created\n",
      "\n",
      "at least one new workspace, been granted access to a workspace, or you've added an\n",
      "\n",
      "item to My workspace, you might find it more convenient to navigate directly to a\n",
      "\n",
      "workspace. One way to navigate to a workspace is by using the nav pane and workspace\n",
      "\n",
      "selector.\n",
      "\n",
      "\fTo open Home, select it from the top of your left navigation pane.\n",
      "\n",
      "Most important content at your fingertips\n",
      "\n",
      "The items that you can access appear on Home. If your Home canvas gets crowded, use\n",
      "\n",
      "global search to find what you need, quickly. The layout and content on Home is\n",
      "\n",
      "different for every user and every product experience, but there are numerous\n",
      "\n",
      "similarities as well. These similarities are listed here and discussed in more detail later in\n",
      "\n",
      "this article.\n",
      "\n",
      "７ Note\n",
      "\n",
      "Power BI Home is different from the other product experiences. To learn more, visit\n",
      "\n",
      "Power BI Home.\n",
      "\n",
      "\f1. The left navigation pane (nav pane) for your product experience links you to\n",
      "\n",
      "different views of your items and to creator resources.\n",
      "\n",
      "2. The selector for switching product experiences.\n",
      "\n",
      "3. The top menu bar for orienting yourself in Microsoft Fabric, finding items, help,\n",
      "\n",
      "and sending Microsoft feedback. The Account manager control is a critical icon for\n",
      "\n",
      "looking up your account information and managing your Fabric trial.\n",
      "\n",
      "4. Options for creating new items.\n",
      "\n",
      "5. Links to recommended content. This content helps you get started using the\n",
      "\n",
      "product experience and links to items and workspaces that you visit often.\n",
      "\n",
      "6. Your items organized by recent, favorites, and items shared with you by your\n",
      "\n",
      "colleagues. The items that appear here are the same across product experiences,\n",
      "\n",
      "with the exception of the Power BI experience.\n",
      "\n",
      "） Important\n",
      "\n",
      "Only the content that you can access appears on your Home. For example, if you\n",
      "\n",
      "don't have permissions to a report, that report doesn't appear on Home. The\n",
      "\n",
      "exception to this is if your subscription or license changes to one with less access,\n",
      "\n",
      "then you will receive a prompt asking you to start a trial or upgrade your license.\n",
      "\n",
      "\fLocate items from Home\n",
      "\n",
      "Microsoft Fabric offers many ways of locating and viewing your content. All approaches\n",
      "\n",
      "access the same pool of content in different ways. Searching is sometimes the easiest\n",
      "\n",
      "and quickest way to find something. While other times, using the nav pane to open a\n",
      "\n",
      "workspace or selecting a card on the Home canvas is your best option.\n",
      "\n",
      "Use the navigation pane\n",
      "\n",
      "\fAlong the left side is a narrow vertical bar, referred to as the nav pane. This example\n",
      "\n",
      "uses the Data factory nav pane. Notice that My workspace is the active workspace. The\n",
      "\n",
      "options in your nav pane depend on the product experience you've selected. The nav\n",
      "\n",
      "pane organizes actions you can take with your items in ways that help you get to where\n",
      "\n",
      "\fyou want to be quickly. Occasionally, using the nav pane is the quickest way to get to\n",
      "\n",
      "your items.\n",
      "\n",
      "In the bottom section of the nav pane is where you find and open your workspaces. Use\n",
      "\n",
      "the workspace selector to view a list of your workspaces and select one to open. Below\n",
      "\n",
      "the workspace selector is the name of the currently open workspace. \n",
      "\n",
      "- By default, you see the Workspaces selector and My workspace. \n",
      "\n",
      "- When you open a workspace, its name replaces My workspace. \n",
      "\n",
      "- Whenever you create a new item, it's added to the open workspace.\n",
      "\n",
      "The nav pane is there when you open Home and remains there as you open other areas\n",
      "\n",
      "of Microsoft Fabric. Every Microsoft Fabric product experience nav pane includes Home,\n",
      "\n",
      "Browse, OneLake data hub, Create, and Workspaces.\n",
      "\n",
      "Find and open workspaces\n",
      "\n",
      "Workspaces are places to collaborate with colleagues to create collections of items such\n",
      "\n",
      "as lakehouses, warehouses, and reports.\n",
      "\n",
      "There are different ways to find and open your workspaces. If you know the name or\n",
      "\n",
      "owner, you can search. Or you can select the Workspaces icon in the nav pane and\n",
      "\n",
      "choose which workspace to open.\n",
      "\n",
      "\fThe workspace opens on your canvas, and the name of the workspace is listed on your\n",
      "\n",
      "nav pane. When you open a workspace, you can view its content. It includes items such\n",
      "\n",
      "as notebooks, pipelines, reports, and lakehouses.\n",
      "\n",
      "For more information, see Workspaces.\n",
      "\n",
      "Find and open other product experiences\n",
      "\n",
      "\fIn the bottom left corner is your experience selector. Click the icon to see all of the\n",
      "\n",
      "available Microsoft Fabric product experiences. Select an experience to open it and\n",
      "\n",
      "make it active.\n",
      "\n",
      "Find your content using search, sort, and filter\n",
      "\n",
      "To learn about the many ways to search from Microsoft Fabric, see Searching and\n",
      "\n",
      "sorting. Global searching is available by item, name, keyword, workspace, and more.\n",
      "\n",
      "Find answers in the context sensitive Help pane\n",
      "\n",
      "Select the Help icon (?) to open and use the contextual Help pane and to search for\n",
      "\n",
      "answers to questions.\n",
      "\n",
      "Microsoft Fabric provides context sensitive help in the right rail of your browser. In this\n",
      "\n",
      "example, we've selected Browse from the nav pane and the Help pane automatically\n",
      "\n",
      "updates to show us articles about the features of the Browse screen. For example, we're\n",
      "\n",
      "\fshown articles on View recent content and See content that others have shared with you.\n",
      "\n",
      "If there are community posts related to the current view, they're displayed under Forum\n",
      "\n",
      "topics.\n",
      "\n",
      "Leave the Help pane open as you work, and use the suggested topics to learn how to\n",
      "\n",
      "use Microsoft Fabric features and terminology. Or, select the X to close the Help pane\n",
      "\n",
      "and save screen space.\n",
      "\n",
      "The Help pane is also a great place to search for answers to your questions. Type in the\n",
      "\n",
      "Search field and your answers are listed below.\n",
      "\n",
      "\f\fTo return to the default Help pane, select the left arrow.\n",
      "\n",
      "For more information about searching, see Searching and sorting.\n",
      "\n",
      "For more information about the Help pane, see Get in-product help.\n",
      "\n",
      "Find help and support\n",
      "\n",
      "If the self-help answers don't resolve your issue, scroll to the bottom of the Help pane\n",
      "\n",
      "for more resources. Use the links to ask the community for help or to connect with\n",
      "\n",
      "Microsoft Fabric Support. For more information about contacting Support, see Support\n",
      "\n",
      "options.\n",
      "\n",
      "Find your account and license information\n",
      "\n",
      "Information about your account and license is available from the Account manager.\n",
      "\n",
      "Select the tiny photo from the upper right corner of Microsoft Fabric to open your\n",
      "\n",
      "Account manager.\n",
      "\n",
      "\fFor more information about licenses and trials, see Licenses.\n",
      "\n",
      "Find notifications, settings, and feedback\n",
      "\n",
      "In the upper right corner of Home are several helpful icons. Take time to explore your\n",
      "\n",
      "Notifications center, Settings, and Feedback options. The ? icon displays your Help and\n",
      "\n",
      "search options and the Account manager icon displays information about your account\n",
      "\n",
      "and license. Both of these features are described in detail earlier in this article.\n",
      "\n",
      "Find what you need on your Home canvas\n",
      "\n",
      "The final section of Home is the center area, called the canvas. The content of your\n",
      "\n",
      "canvas updates as you select different items. By default, the Home canvas displays\n",
      "\n",
      "options for creating new items, recommended items, recents, favorites, and content that\n",
      "\n",
      "has been shared with you. If you've selected the Show less view, the New section of the\n",
      "\n",
      "canvas is collapsed.\n",
      "\n",
      "\fWhen you create a new item, it's saved in your My workspace unless you've selected a\n",
      "\n",
      "workspace from Workspaces. To learn more about creating items in workspaces, see\n",
      "\n",
      "create workspaces.\n",
      "\n",
      "７ Note\n",
      "\n",
      "Power BI Home is different from the other product experiences. To learn more, visit\n",
      "\n",
      "Power BI Home.\n",
      "\n",
      "The Recommended area might include getting started content as well as items and\n",
      "\n",
      "workspaces that you use frequently.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Power BI Home\n",
      "\n",
      "Start a Fabric trial\n",
      "\n",
      "\fSelf-help with the Fabric contextual\n",
      "Help pane\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "This article explains how to use the Fabric Help pane. The Help pane is feature-aware\n",
      "\n",
      "and displays articles about the actions and features available on the current Fabric\n",
      "\n",
      "screen. The Help pane is also a search engine that quickly finds answers to questions in\n",
      "\n",
      "the Fabric documentation and Fabric community forums.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "The Help pane is feature-aware\n",
      "\n",
      "The feature-aware state is the default view of the Help pane when you open it without\n",
      "\n",
      "entering any search terms. The Help pane shows a list of recommended topics,\n",
      "\n",
      "resources that are relevant to your current context and location in Fabric, and a list of\n",
      "\n",
      "links for other resources. It has three sections:\n",
      "\n",
      "\fFeature-aware documents: This section groups the documents by the features\n",
      "\n",
      "that are available on the current screen. Select a feature in the Fabric screen and\n",
      "\n",
      "the Help pane updates with documents related to that feature. Select a document\n",
      "\n",
      "to open it in a separate browser tab.\n",
      "\n",
      "Forum topics: This section shows topics from the community forums that are\n",
      "\n",
      "related to the features on the current screen. Select a topic to open it in a separate\n",
      "\n",
      "browser tab.\n",
      "\n",
      "Other resources: This section has links for feedback and Support.\n",
      "\n",
      "The Help pane is a search engine\n",
      "\n",
      "The Help pane is also a search engine. Enter a keyword to find relevant information and\n",
      "\n",
      "resources from Microsoft documentation and community forum topics. Use the\n",
      "\n",
      "dropdown to filter the results.\n",
      "\n",
      "\fThe Help pane is perfect for learning and\n",
      "getting started\n",
      "\n",
      "As you explore Fabric, the feature-aware documents update based on what you've\n",
      "\n",
      "selected and where you are in Fabric. This is a great way to learn how to use Fabric. Give\n",
      "\n",
      "yourself a guided tour by making selections in Fabric and reading the feature-aware\n",
      "\n",
      "documents. For example, in the Data Science experience, select OneLake data hub. The\n",
      "\n",
      "Help pane updates with articles that you can use to learn about the data hub.\n",
      "\n",
      "\fOpen the Help pane\n",
      "\n",
      "Follow the instructions to practice using the Help pane.\n",
      "\n",
      "1. From the upper-right corner of Fabric, select the ? icon to open the Help pane.\n",
      "\n",
      "2. Open Browse and select the Recent feature. The Fabric Help pane displays\n",
      "\n",
      "documents about the Recent feature. Select a document to learn more. The\n",
      "\n",
      "\fdocument opens in a separate browser tab.\n",
      "\n",
      "3. Forum posts often provide interesting context. Select one that looks helpful or\n",
      "\n",
      "interesting.\n",
      "\n",
      "4. Search the Microsoft documentation and community forums by entering a\n",
      "\n",
      "keyword in the search pane.\n",
      "\n",
      "\f5. Return to the default display of the Help pane by selecting the arrow.\n",
      "\n",
      "6. Close the Help pane by selecting the X icon in the upper-right corner of the pane.\n",
      "\n",
      "\fStill need help?\n",
      "\n",
      "If you still need help, select Ask the community and submit a question. If you have an\n",
      "\n",
      "idea for a new feature, let us know by selecting Submit an idea. To open the Support\n",
      "\n",
      "site, select Get help in Other Resources.\n",
      "\n",
      "\fGlobal search\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "When you're new to Microsoft Fabric, you have only a few items (workspaces, reports,\n",
      "\n",
      "apps, lakehouses). But as you begin creating and sharing items, you can end up with\n",
      "\n",
      "long lists of content. That's when searching, filtering, and sorting become helpful.\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Search for content\n",
      "\n",
      "At the top of Home, the global search box finds items by title, name, or keyword.\n",
      "\n",
      "Sometimes, the fastest way to find an item is to search for it. For example, if a\n",
      "\n",
      "dashboard you haven't used in a while isn't showing up on your Home canvas. Or, if\n",
      "\n",
      "your colleague shared something with you, but you don't remember what it's named or\n",
      "\n",
      "what type of content they shared. Sometimes, you might have so much content that it's\n",
      "\n",
      "easier to search for it rather than scrolling or sorting.\n",
      "\n",
      "Search is available from Home and also most other areas of Microsoft Fabric. Just look\n",
      "\n",
      "for the search box or search icon \n",
      "\n",
      " .\n",
      "\n",
      "In the Search field, type all or part of the name of an item, creator, keyword, or\n",
      "\n",
      "workspace. You can even enter your colleague's name to search for content that they've\n",
      "\n",
      "shared with you. The search finds matches in all the items that you own or have access\n",
      "\n",
      "to.\n",
      "\n",
      "\fIn addition to the Search field, most experiences on the Microsoft Fabric canvas also\n",
      "\n",
      "include a Filter by keyword field. Similar to search, use Filter by keyword to narrow\n",
      "\n",
      "down the content on your canvas to find what you need. The keywords you enter in the\n",
      "\n",
      "Filter by keyword pane apply to the current view only. For example, if you open Browse\n",
      "\n",
      "and enter a keyword in the Filter by keyword pane, Microsoft Fabric searches only the\n",
      "\n",
      "content that appears on the Browse canvas.\n",
      "\n",
      "Sort content lists\n",
      "\n",
      "If you have only a few items, sorting isn't necessary. But when you have long lists of\n",
      "\n",
      "items, sorting helps you find what you need. For example, this Shared with me content\n",
      "\n",
      "list has many items.\n",
      "\n",
      "\fRight now, this content list is sorted alphabetical by name, from Z to A. To change the\n",
      "\n",
      "sort criteria, select the arrow to the right of Name.\n",
      "\n",
      "Sorting is also available in other areas of Microsoft Fabric. In this example, the\n",
      "\n",
      "workspaces are sorted by the Refreshed date. To set sorting criteria for workspaces,\n",
      "\n",
      "select a column header, and then select again to change the sorting direction.\n",
      "\n",
      "\fNot all columns can be sorted. Hover over the column headings to discover which can\n",
      "\n",
      "be sorted.\n",
      "\n",
      "Filter content lists\n",
      "\n",
      "Another way to locate content quickly is to use the content list Filter. Display the filters\n",
      "\n",
      "by selecting Filter from the upper right corner. The filters available depend on your\n",
      "\n",
      "location in Microsoft Fabric. This example is from a Recent content list. It allows you to\n",
      "\n",
      "filter the list by content Type, Time, or Owner.\n",
      "\n",
      "\fNext steps\n",
      "\n",
      "Find Fabric items from Home\n",
      "\n",
      "Start a Fabric trial\n",
      "\n",
      "\fFabric settings\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "The Fabric settings pane provides links to various kinds of settings you can configure.\n",
      "\n",
      "This article shows how to open the Fabric settings pane and describes the kinds of\n",
      "\n",
      "settings you can access from there.\n",
      "\n",
      "Open the Fabric settings pane\n",
      "\n",
      "To open the Fabric settings pane, select the gear icon in the Fabric portal header.\n",
      "\n",
      "Preferences\n",
      "\n",
      "In the preferences section, individual users can set their user preferences, specify the\n",
      "\n",
      "language of the Fabric user interface, manage their account and notifications, and\n",
      "\n",
      "configure settings for their personal use throughout the system.\n",
      "\n",
      "Link\n",
      "\n",
      "Description\n",
      "\n",
      "General\n",
      "\n",
      "Opens the generate settings page, where you can set the display language for the\n",
      "\n",
      "Fabric interface and parts of visuals.\n",
      "\n",
      "Notifications Opens the notifications settings page where you can view your subscriptions and\n",
      "\n",
      "alerts.\n",
      "\n",
      "\fLink\n",
      "\n",
      "Description\n",
      "\n",
      "Item\n",
      "\n",
      "settings\n",
      "\n",
      "Opens the item settings page, where you can configure per-item-type settings.\n",
      "\n",
      "Developer\n",
      "settings\n",
      "\n",
      "Opens the developer settings page, where you can configure developer mode\n",
      "settings.\n",
      "\n",
      "Resources and extensions\n",
      "\n",
      "The resources and extensions section provides links to pages where users can use\n",
      "\n",
      "following capabilities.\n",
      "\n",
      "Link\n",
      "\n",
      "Description\n",
      "\n",
      "Manage\n",
      "personal/group\n",
      "\n",
      "Opens the personal/group storage management page, where you can see and\n",
      "manage data items that you own or that have been shared with you.\n",
      "\n",
      "storage\n",
      "\n",
      "Power BI\n",
      "\n",
      "settings\n",
      "\n",
      "Opens the Power BI settings page, where you can get to the settings pages for\n",
      "\n",
      "the Power BI items (dashboards, datasets, workbooks, reports, datamarts, and\n",
      "\n",
      "dataflows) that are in the current workspace.\n",
      "\n",
      "Manage\n",
      "\n",
      "Opens page where you can manage connections, on-premises data gateways,\n",
      "\n",
      "connections\n",
      "and gateways\n",
      "\n",
      "Manage\n",
      "embed codes\n",
      "\n",
      "and virtual networks data gateways.\n",
      "\n",
      "Opens a page where you can manage embed codes you have created.\n",
      "\n",
      "Azure Analysis\n",
      "Services\n",
      "\n",
      "Opens up a page where you can migrate your Azure Analysis Services datasets\n",
      "to Power BI Premium.\n",
      "\n",
      "migrations\n",
      "\n",
      "Governance and insights settings\n",
      "\n",
      "The governance and insights section provides links to help admins and users with their\n",
      "\n",
      "admin, governance, and compliance tasks.\n",
      "\n",
      "Link\n",
      "\n",
      "Description\n",
      "\n",
      "Admin\n",
      "\n",
      "portal\n",
      "\n",
      "Opens the Fabric admin portal where admins perform various management tasks and\n",
      "\n",
      "configure Fabric tenant settings. For more information, see What is the admin portal?\n",
      "\n",
      "\fLink\n",
      "\n",
      "Description\n",
      "\n",
      "Microsoft\n",
      "Purview\n",
      "\n",
      "Currently available to Power BI admins only. Opens the Microsoft Purview hub where\n",
      "you can view Purview insights about your organization's sensitive data. The Microsoft\n",
      "\n",
      "hub\n",
      "\n",
      "Purview hub also provides links to Purview governance and compliance capabilities\n",
      "\n",
      "(preview)\n",
      "\n",
      "and has links to documentation to help you get started with Microsoft Purview\n",
      "governance and compliance in Fabric.\n",
      "\n",
      "Next steps\n",
      "\n",
      "What is Fabric\n",
      "\n",
      "What is Microsoft Fabric admin?\n",
      "\n",
      "\fWorkspaces\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Workspaces are places to collaborate with colleagues to create collections of items such\n",
      "\n",
      "as lakehouses, warehouses, and reports. This article describes workspaces, how to\n",
      "\n",
      "manage access to them, and what settings are available.\n",
      "\n",
      "Ready to get started? Read Create a workspace.\n",
      "\n",
      "\n",
      "\n",
      "Working with workspaces\n",
      "\n",
      "Here are some useful tips about working with workspaces.\n",
      "\n",
      "Pin workspaces to the top of the workspace flyout list to quickly access your\n",
      "\n",
      "favorite workspaces. Read more about pin workspaces.\n",
      "\n",
      "Use granular workspace roles for flexible permissions management in the\n",
      "\n",
      "workspaces: Admin, Member, Contributor, and Viewer. Read more about\n",
      "\n",
      "workspace roles.\n",
      "\n",
      "Navigate to current workspace from anywhere by selecting the icon on left nav\n",
      "\n",
      "pane. Read more about current workspace in this article.\n",
      "\n",
      "Workspace settings: As workspace admin, you can update and manage your\n",
      "\n",
      "workspace configurations in workspace settings.\n",
      "\n",
      "Contact list: Specify who receives notification about workspace activity. Read more\n",
      "\n",
      "about workspace contact lists in this article.\n",
      "\n",
      "\fCurrent workspace\n",
      "\n",
      "After you select and open to a workspace, this workspace becomes your current\n",
      "\n",
      "workspace. You can quickly navigate to it from anywhere by selecting the workspace\n",
      "\n",
      "icon from left nav pane.\n",
      "\n",
      "Workspace settings\n",
      "\n",
      "Workspace admins can use workspace settings to manage and update the workspace.\n",
      "\n",
      "The settings include general settings of the workspace, like the basic information of the\n",
      "\n",
      "workspace, contact list, OneDrive, license, Azure connections, storage, and other\n",
      "\n",
      "experiences' specific settings.\n",
      "\n",
      "To open the workspace settings, you can select the workspace in the nav pane, then\n",
      "\n",
      "select More options (...) > Workspace settings next to the workspace name.\n",
      "\n",
      "\fYou can also open it from the workspace page.\n",
      "\n",
      "\f\n",
      "\n",
      "Workspace contact list\n",
      "\n",
      "The Contact list feature allows you to specify which users receive notification about\n",
      "\n",
      "issues occurring in the workspace. By default, the one who created the workspace is in\n",
      "\n",
      "the contact list. You can add others to that list while creating workspace or in workspace\n",
      "\n",
      "settings after creation. Users or groups in the contact list are also listed in the user\n",
      "\n",
      "interface (UI) of the workspace settings, so workspace users know whom to contact.\n",
      "\n",
      "Microsoft 365 and OneDrive\n",
      "\n",
      "The Workspace OneDrive feature allows you to configure a Microsoft 365 Group whose\n",
      "\n",
      "SharePoint document library is available to workspace users. You create the Group\n",
      "\n",
      "\foutside of Microsoft Fabric first, with one available method being from OneDrive. Read\n",
      "\n",
      "about creating a OneDrive shared library\n",
      "\n",
      ".\n",
      "\n",
      "７ Note\n",
      "\n",
      "Creating Microsoft 365 Groups may be restricted in your environment, or the ability\n",
      "\n",
      "to create them from your OneDrive site may be disabled. If this is the case, speak\n",
      "\n",
      "with your IT department.\n",
      "\n",
      "Microsoft Fabric doesn't synchronize permissions between users or groups with\n",
      "\n",
      "workspace access, and users or groups with Microsoft 365 Group membership. A best\n",
      "\n",
      "practice is to give access to the workspace to the same Microsoft 365 Group whose file\n",
      "\n",
      "storage you configured. Then manage workspace access by managing membership of\n",
      "\n",
      "the Microsoft 365 Group.\n",
      "\n",
      "You can configure OneDrive in workspace settings by typing in the name of the\n",
      "\n",
      "Microsoft 365 group that you created earlier. Type just the name, not the URL. Microsoft\n",
      "\n",
      "Fabric automatically picks up the OneDrive for the group.\n",
      "\n",
      "License mode\n",
      "\n",
      "By default, workspaces are created in your organization's shared capacity. When your\n",
      "\n",
      "organization has other capacities, workspaces including My Workspaces can be assigned\n",
      "\n",
      "to any capacity in your organization. You can configure it while creating a workspace or\n",
      "\n",
      "in Workspace settings -> Premium. Read more about licenses.\n",
      "\n",
      "\fAzure connections configuration\n",
      "\n",
      "Workspace admins can configure dataflow storage to use Azure Data Lake Gen 2\n",
      "\n",
      "storage and Azure Log Analytics (LA) connection to collect usage and performance logs\n",
      "\n",
      "for the workspace in workspace settings.\n",
      "\n",
      "\n",
      "\n",
      "\fWith the integration of Azure Data Lake Gen 2 storage, you can bring your own storage\n",
      "\n",
      "to dataflows, and establish a connection at the workspace level. Read Configure\n",
      "\n",
      "dataflow storage to use Azure Data Lake Gen 2 for more detail.\n",
      "\n",
      "After the connection with Azure Log Analytics (LA), activity log data is sent continuously\n",
      "\n",
      "and is available in Log Analytics in approximately 5 minutes. Read Using Azure Log\n",
      "\n",
      "Analytics for more detail.\n",
      "\n",
      "System storage\n",
      "\n",
      "System storage is the place to manage your dataset storage in your individual or\n",
      "\n",
      "workspace account so you can keep publishing reports and datasets. Your own datasets,\n",
      "\n",
      "Excel reports, and those items that someone has shared with you, are included in your\n",
      "\n",
      "system storage.\n",
      "\n",
      "In the system storage, you can view how much storage you have used and free up the\n",
      "\n",
      "storage by deleting the items in it.\n",
      "\n",
      "Keep in mind that you or someone else may have reports and dashboards based on a\n",
      "\n",
      "dataset. If you delete the dataset, those reports and dashboards don't work anymore.\n",
      "\n",
      "\n",
      "\n",
      "\fRemove the workspace\n",
      "\n",
      "As an admin for a workspace, you can delete it. When you delete the workspace,\n",
      "\n",
      "everything contained within the workspace is deleted for all group members, and the\n",
      "\n",
      "associated app is also removed from AppSource.\n",
      "\n",
      "In the Workspace settings pane, select Other > Remove this workspace.\n",
      "\n",
      "\n",
      "\n",
      "Administering and auditing workspaces\n",
      "\n",
      "Administration for workspaces is in the Microsoft Fabric admin portal. Microsoft Fabric\n",
      "\n",
      "admins decide who in an organization can create workspaces and distribute apps. Read\n",
      "\n",
      "about managing users' ability to create workspaces in the \"Workspace settings\" article.\n",
      "\n",
      "Admins can also see the state of all the workspaces in their organization. They can\n",
      "\n",
      "manage, recover, and even delete workspaces. Read about managing the workspaces\n",
      "\n",
      "themselves in the \"Admin portal\" article.\n",
      "\n",
      "Auditing\n",
      "\n",
      "Microsoft Fabric audits the following activities for workspaces.\n",
      "\n",
      "Friendly name\n",
      "\n",
      "Created Microsoft Fabric folder\n",
      "\n",
      "Deleted Microsoft Fabric folder\n",
      "\n",
      "Operation name\n",
      "\n",
      "CreateFolder\n",
      "\n",
      "DeleteFolder\n",
      "\n",
      "\fFriendly name\n",
      "\n",
      "Operation name\n",
      "\n",
      "Updated Microsoft Fabric folder\n",
      "\n",
      "UpdateFolder\n",
      "\n",
      "Updated Microsoft Fabric folder access\n",
      "\n",
      "UpdateFolderAccess\n",
      "\n",
      "Read more about Microsoft Fabric auditing.\n",
      "\n",
      "Considerations and limitations\n",
      "\n",
      "Limitations to be aware of:\n",
      "\n",
      "Workspaces can contain a maximum of 1,000 datasets, or 1,000 reports per\n",
      "\n",
      "dataset.\n",
      "\n",
      "Certain special characters aren't supported in workspace names when using an\n",
      "\n",
      "XMLA endpoint. As a workaround, use URL encoding of special characters, for\n",
      "\n",
      "example, for a forward slash /, use %2F.\n",
      "\n",
      "A user or a service principal can be a member of up to 1,000 workspaces.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Create workspaces\n",
      "\n",
      "Give users access to workspaces\n",
      "\n",
      "\fCreate a workspace\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "This article explains how to create workspaces in Microsoft Fabric. In workspaces, you\n",
      "\n",
      "create collections of items such as lakehouses, warehouses, and reports. For more\n",
      "\n",
      "background, see the Workspaces article.\n",
      "\n",
      "To create a workspace:\n",
      "\n",
      "1. Select Workspaces > New workspace. The Create a workspace pane opens.\n",
      "\n",
      "2. The Create a workspace pane opens.\n",
      "\n",
      "\fGive the workspace a unique name (mandatory).\n",
      "\n",
      "Provide a description of the workspace (optional).\n",
      "\n",
      "Assign the workspace to a domain (optional).\n",
      "\n",
      "If you are a domain contributor for the workspace, you can associate the\n",
      "\n",
      "workspace to a domain, or you can change an existing association. For\n",
      "\n",
      "information about domains, see Domains in Fabric.\n",
      "\n",
      "3. When done, either continue to the advanced settings, or select Apply.\n",
      "\n",
      "Advanced settings\n",
      "\n",
      "Expand Advanced and you see advanced setting options:\n",
      "\n",
      "Contact list\n",
      "\n",
      "\fContact list is a place where you can put the names of people as contacts for\n",
      "\n",
      "information about the workspace. Accordingly, people in this contact list receive system\n",
      "\n",
      "email notifications for workspace level changes.\n",
      "\n",
      "By default, the first workspace admin who created the workspace is the contact. You can\n",
      "\n",
      "add other users or groups according to your needs. Enter the name in the input box\n",
      "\n",
      "directly, it helps you to automatically search and match users or groups in your org.\n",
      "\n",
      "License mode\n",
      "\n",
      "Different license mode provides different sets of feature for your workspace. After the\n",
      "\n",
      "creation, you can still change the workspace license type in workspace settings, but\n",
      "\n",
      "some migration effort is needed.\n",
      "\n",
      "７ Note\n",
      "\n",
      "Currently, if you want to downgrade the workspace license type from Premium\n",
      "\n",
      "capacity to Pro (Shared capacity), you must first remove any non-Power BI Fabric\n",
      "\n",
      "items that the workspace contains. Only after you remove such items will you be\n",
      "\n",
      "allowed to downgrade the capacity. For more information, see Moving data\n",
      "\n",
      "around.\n",
      "\n",
      "Default storage format\n",
      "\n",
      "Power BI datasets can store data in a highly compressed in-memory cache for optimized\n",
      "\n",
      "query performance, enabling fast user interactivity. With Premium capacities, large\n",
      "\n",
      "datasets beyond the default limit can be enabled with the Large dataset storage format\n",
      "\n",
      "setting. When enabled, dataset size is limited by the Premium capacity size or the\n",
      "\n",
      "maximum size set by the administrator. Learn more about large dataset storage format.\n",
      "\n",
      "Template apps\n",
      "\n",
      "Power BI template apps are developed for sharing outside your organization. If you\n",
      "\n",
      "check this option, a special type of workspace (template app workspace) is created. It's\n",
      "\n",
      "not possible to revert it back to a normal workspace after creation.\n",
      "\n",
      "\fDataflow storage (preview)\n",
      "\n",
      "Data used with Power BI is stored in internal storage provided by Power BI by default.\n",
      "\n",
      "With the integration of dataflows and Azure Data Lake Storage Gen 2 (ADLS Gen2), you\n",
      "\n",
      "can store your dataflows in your organization's Azure Data Lake Storage Gen2 account.\n",
      "\n",
      "Learn more about dataflows in Azure Data Lake Storage Gen2 accounts.\n",
      "\n",
      "Give users access to your workspace\n",
      "\n",
      "Now that you've created the workspace, you'll want to add other users to roles in the\n",
      "\n",
      "workspace, so you can collaborate with them. See these articles for more information:\n",
      "\n",
      "Give users access to a workspace\n",
      "\n",
      "Roles in workspaces\n",
      "\n",
      "Pin workspaces\n",
      "\n",
      "Quickly access your favorite workspaces by pinning them to the top of the workspace\n",
      "\n",
      "flyout list.\n",
      "\n",
      "1. Open the workspace flyout from the nav pane and hover over the workspace you\n",
      "\n",
      "want to pin. Select the Pin to top icon.\n",
      "\n",
      "\f2. The workspace is added in the Pinned list.\n",
      "\n",
      "\f3. To unpin a workspace, select the unpin button. The workspace is unpinned.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Read about workspaces\n",
      "\n",
      "\fRoles in workspaces\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Workspace roles let you manage who can do what in a Microsoft Fabric workspace.\n",
      "\n",
      "Microsoft Fabric workspaces sit on top of OneLake and divide the data lake into\n",
      "\n",
      "separate containers that can be secured independently. Workspace roles in Microsoft\n",
      "\n",
      "Fabric extend the Power BI workspace roles by associating new Microsoft Fabric\n",
      "\n",
      "capabilities such as data integration and data exploration with existing workspace roles.\n",
      "\n",
      "For more information on Power BI roles, see Roles in workspaces in Power BI.\n",
      "\n",
      "You can either assign roles to individuals or to security groups, Microsoft 365 groups,\n",
      "\n",
      "and distribution lists. To grant access to a workspace, assign those user groups or\n",
      "\n",
      "individuals to one of the workspace roles: Admin, Member, Contributor, or Viewer.\n",
      "\n",
      "Here's how to give users access to workspaces.\n",
      "\n",
      "To create a new workspace, see Create a workspace.\n",
      "\n",
      "Everyone in a user group gets the role that you've assigned. If someone is in several user\n",
      "\n",
      "groups, they get the highest level of permission that's provided by the roles that they're\n",
      "\n",
      "assigned. If you nest user groups and assign a role to a group, all the contained users\n",
      "\n",
      "have permissions.\n",
      "\n",
      "Users in workspace roles have the following Microsoft Fabric capabilities, in addition to\n",
      "\n",
      "the existing Power BI capabilities associated with these roles.\n",
      "\n",
      "Microsoft Fabric workspace roles\n",
      "\n",
      "Capability\n",
      "\n",
      "Admin Member Contributor Viewer\n",
      "\n",
      "View and read content of data pipelines,\n",
      "\n",
      "notebooks, Spark job definitions, ML models and\n",
      "experiments, and Event streams.\n",
      "\n",
      "View and read content of KQL databases, KQL\n",
      "query-sets, and real-time dashboards.\n",
      "\n",
      "Connect to SQL endpoints of Lakehouse and Data\n",
      "\n",
      "warehouse.\n",
      "\n",
      "Read Lakehouse and Data warehouse data and\n",
      "\n",
      "shortcuts  through SQL endpoints.\n",
      "\n",
      "1\n",
      "\n",
      "Read Lakehouse and Data warehouse data and\n",
      "\n",
      "shortcuts  through OneLake APIs and Spark.\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "\fCapability\n",
      "\n",
      "Admin Member Contributor Viewer\n",
      "\n",
      "Read Lakehouse data through Lakehouse explorer.\n",
      "\n",
      "Write or delete data pipelines, notebooks, Spark\n",
      "\n",
      "job definitions, ML models and experiments, and\n",
      "Event streams.\n",
      "\n",
      "Write or delete KQL query-sets, real-time\n",
      "\n",
      "dashboards, and schema and data of KQL\n",
      "databases, Lakehouses, data warehouses, and\n",
      "\n",
      "shortcuts.\n",
      "\n",
      "Execute or cancel execution of notebooks, Spark\n",
      "job definitions, ML models and experiments.\n",
      "\n",
      "Execute or cancel execution of data pipelines.\n",
      "\n",
      "View execution output of data pipelines,\n",
      "\n",
      "notebooks, ML models and experiments.\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "1\n",
      " Additional permissions are needed to read data from shortcut destination. Learn more\n",
      "\n",
      "about shortcut security model.\n",
      "\n",
      "2\n",
      " Admins, Members, and Contributors can grant viewers granular SQL permissions to\n",
      "\n",
      "read Lakehouse and Data warehouse data through SQL endpoints.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Roles in workspaces in Power BI\n",
      "\n",
      "Create workspaces\n",
      "\n",
      "Give users access to workspaces\n",
      "\n",
      "OneLake security\n",
      "\n",
      "OneLake shortcuts\n",
      "\n",
      "Data warehouse security\n",
      "\n",
      "Data engineering security\n",
      "\n",
      "Data science roles and permissions\n",
      "\n",
      "\fGive users access to workspaces\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "After you create a workspace in Microsoft Fabric, or if you have an admin or member\n",
      "\n",
      "role in a workspace, you can give others access to it by adding them to the different\n",
      "\n",
      "roles. Workspace creators are automatically admins. For an explanation of the different\n",
      "\n",
      "roles, see Roles in workspaces.\n",
      "\n",
      "７ Note\n",
      "\n",
      "To enforce row-level security (RLS) on Power BI items for Microsoft Fabric Pro users\n",
      "\n",
      "who browse content in a workspace, assign them the Viewer Role.\n",
      "\n",
      "After you add or remove workspace access for a user or a group, the permission\n",
      "\n",
      "change only takes effect the next time the user logs into Microsoft Fabric.\n",
      "\n",
      "Give access to your workspace\n",
      "\n",
      "1. Because you have the Admin or Member role in the workspace, on the command\n",
      "\n",
      "bar of workspace page, you see Manage Access. Sometimes this entry is on the\n",
      "\n",
      "More options (...) menu.\n",
      "\n",
      "Manage access on the More options menu.\n",
      "\n",
      "2. Select Add people or groups.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f3. Enter name or email, select a role, and select Add. You can add security groups,\n",
      "\n",
      "distribution lists, Microsoft 365 groups, or individuals to these workspaces as\n",
      "\n",
      "admins, members, contributors, or viewers. If you have the member role, you can\n",
      "\n",
      "only add others to the member, contributor, or viewer roles.\n",
      "\n",
      "\f4. You can view and modify access later if needed. Use the Search box to search for\n",
      "\n",
      "people or groups who already have access of this workspace. To modify access,\n",
      "\n",
      "select drop-down arrow, and select a role.\n",
      "\n",
      "\fNext steps\n",
      "\n",
      "Read about the workspace experience.\n",
      "\n",
      "Create workspaces.\n",
      "\n",
      "Roles in workspaces\n",
      "\n",
      "\fDiscover data items in the OneLake data\n",
      "hub\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "The OneLake data hub makes it easy to find, explore, and use the Fabric data items in\n",
      "\n",
      "your organization that you have access to. It provides information about the items and\n",
      "\n",
      "entry points for working with them.\n",
      "\n",
      "The data hub provides:\n",
      "\n",
      "A filterable list of all the data items you can access\n",
      "\n",
      "A gallery of recommended data items\n",
      "\n",
      "A way of finding data items by workspace\n",
      "\n",
      "A way to display only the data items of a selected domain\n",
      "\n",
      "An options menu of things you can do with the data item\n",
      "\n",
      "This article explains what you see on the data hub and describes how to use it.\n",
      "\n",
      "\n",
      "\n",
      "Open the data hub\n",
      "\n",
      "To open the data hub, select the OneLake data hub icon in the navigation pane.\n",
      "\n",
      "\fFind items in the data items list\n",
      "\n",
      "The data items list displays all the data items you have access to. To shorten the list, you\n",
      "\n",
      "can filter by keyword or data-item type using the filters at the top of the list. If you\n",
      "\n",
      "select the name of an item, you'll get to the item's details page. If you hover over an\n",
      "\n",
      "item, you'll see three dots that open the options menu when you select them.\n",
      "\n",
      "\n",
      "\n",
      "The list has three tabs to narrow down the list of data items.\n",
      "\n",
      "Tab\n",
      "\n",
      "All\n",
      "\n",
      "Description\n",
      "\n",
      "Data items that you're allowed to find.\n",
      "\n",
      "My data\n",
      "\n",
      "Data items that you own.\n",
      "\n",
      "Endorsed\n",
      "in your\n",
      "\n",
      "Endorsed data items in your organization that you're allowed to find. Certified data\n",
      "items are listed first, followed by promoted data items. For more information about\n",
      "\n",
      "org\n",
      "\n",
      "endorsement, see the Endorsement overview\n",
      "\n",
      "The columns of the list are described below.\n",
      "\n",
      "Column\n",
      "\n",
      "Description\n",
      "\n",
      "Name\n",
      "\n",
      "The data item name. Select the name to open the item's details page.\n",
      "\n",
      "Endorsement\n",
      "\n",
      "Endorsement status.\n",
      "\n",
      "\fColumn\n",
      "\n",
      "Description\n",
      "\n",
      "Owner\n",
      "\n",
      "Data item owner (listed in the All and Endorsed in your org tabs only).\n",
      "\n",
      "Workspace\n",
      "\n",
      "The workspace the data item is located in.\n",
      "\n",
      "Refreshed\n",
      "\n",
      "Last refresh time (rounded to hour, day, month, and year. See the details section\n",
      "\n",
      "on the item's detail page for the exact time of the last refresh).\n",
      "\n",
      "Next refresh\n",
      "\n",
      "The time of the next scheduled refresh (My data tab only).\n",
      "\n",
      "Sensitivity\n",
      "\n",
      "Sensitivity, if set. Select the info icon to view the sensitivity label description.\n",
      "\n",
      "Find items by workspace\n",
      "\n",
      "Related data items are often grouped together in a workspace. To see the data items by\n",
      "\n",
      "workspace, expand the Explorer pane and select the workspace you're interested in. The\n",
      "\n",
      "data items you're allowed to see in that workspace will be displayed in the data items\n",
      "\n",
      "list.\n",
      "\n",
      "\f７ Note\n",
      "\n",
      "The Explorer pane may list workspaces that you don't have access to if the\n",
      "\n",
      "workspace contains items that you do have access to (through explicitly granted\n",
      "\n",
      "permissions, for example). If you select such a workspace, only the items you have\n",
      "\n",
      "access to will be displayed in the data items list.\n",
      "\n",
      "Find recommended items\n",
      "\n",
      "Use the tiles across the top of the data hub to find and explore recommended data\n",
      "\n",
      "items. Recommended data items are data items that have been certified or promoted by\n",
      "\n",
      "someone in your organization or have recently been refreshed or accessed. Each tile\n",
      "\n",
      "contains information about the item and an options menu for doing things with the\n",
      "\n",
      "item. When you select a recommended tile, you are taken to the item's details page.\n",
      "\n",
      "Display only data items belonging to a\n",
      "particular domain\n",
      "\n",
      "If domains have been defined in your organization, you can use the domain selector to\n",
      "\n",
      "select a domain so that only data items belonging to that domain will be displayed. If an\n",
      "\n",
      "image has been associated with the domain, you’ll see that image on the data hub to\n",
      "\n",
      "remind you of the domain you're viewing.\n",
      "\n",
      "For more information about domains, see the Domains overview\n",
      "\n",
      "Open an item's options menu\n",
      "\n",
      "\fEach item shown in the data hub has an options menu that enables you to do things,\n",
      "\n",
      "such as open the item's settings, manage item permissions, etc. The options available\n",
      "\n",
      "depend on the item and your permissions on the item.\n",
      "\n",
      "To display the options menu, select More options (...) on one of the items shown in the\n",
      "\n",
      "data items list or a recommended item. In the data items list, you need to hover over the\n",
      "\n",
      "item to reveal More options.\n",
      "\n",
      "７ Note\n",
      "\n",
      "The Explorer pane may list workspaces that you don't have access to if the\n",
      "\n",
      "workspace contains items that you do have access to (through explicitly granted\n",
      "\n",
      "permissions, for example). If you select such a workspace, only the items you have\n",
      "\n",
      "access to will be displayed in the data items list.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Navigate to your items from Microsoft Fabric Home\n",
      "\n",
      "Endorsement\n",
      "\n",
      "\fPromote or certify items\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "Fabric provides two ways you can endorse your valuable, high-quality items to increase\n",
      "\n",
      "their visibility: promotion and certification.\n",
      "\n",
      "Promotion: Promotion is a way to highlight items you think are valuable and\n",
      "\n",
      "worthwhile for others to use. It encourages the collaborative use and spread of\n",
      "\n",
      "content within an organization.\n",
      "\n",
      "Any item owner, as well as anyone with write permissions on the item, can\n",
      "\n",
      "promote the item when they think it's good enough for sharing.\n",
      "\n",
      "Certification: Certification means that the item meets the organization's quality\n",
      "\n",
      "standards and can be regarded as reliable, authoritative, and ready for use across\n",
      "\n",
      "the organization.\n",
      "\n",
      "Only authorized reviewers (defined by the Power BI administrator) can certify\n",
      "\n",
      "items. Item owners who wish to see their item certified and aren't authorized to\n",
      "\n",
      "certify it themselves need to follow their organization's guidelines about getting\n",
      "\n",
      "items certified.\n",
      "\n",
      "Currently it's possible to endorse all Fabric items except Power BI dashboards.\n",
      "\n",
      "This article describes how to promote items, how to certify items if you're an authorized\n",
      "\n",
      "reviewer, and how to request certification if you're not.\n",
      "\n",
      "See the endorsement overview to learn more about endorsement.\n",
      "\n",
      "Promote items\n",
      "\n",
      "To promote an item, you must have write permissions on the item you want to promote.\n",
      "\n",
      "1. Go to the settings of the content you want to promote.\n",
      "\n",
      "2. Expand the endorsement section and select Promoted.\n",
      "\n",
      "If you're promoting a Power BI dataset and see a Make discoverable checkbox, it\n",
      "\n",
      "means you can make it possible for users who don't have access to the dataset to\n",
      "\n",
      "find it. See dataset discovery for more detail.\n",
      "\n",
      "\f3. Select Apply.\n",
      "\n",
      "Certify items\n",
      "\n",
      "Item certification is a significant responsibility, and only authorized users can certify\n",
      "\n",
      "items. Other users can request item certification. This section describes how to certify an\n",
      "\n",
      "item.\n",
      "\n",
      "1. Get write permissions on the item you want to certify. You can request these\n",
      "\n",
      "permissions from the item owner or from anyone who as an admin role in\n",
      "\n",
      "workspace where the item is located.\n",
      "\n",
      "2. Carefully review the item and determine whether it meets your organization's\n",
      "\n",
      "certification standards.\n",
      "\n",
      "3. If you decide to certify the item, go to the workspace where it resides, and open\n",
      "\n",
      "the settings of the item you want to certify.\n",
      "\n",
      "4. Expand the endorsement section and select Certified.\n",
      "\n",
      "If you're certifying a Power BI dataset and see a Make discoverable checkbox, it\n",
      "\n",
      "means you can make it possible for users who don't have access to the dataset to\n",
      "\n",
      "find it. See dataset discovery for more detail.\n",
      "\n",
      "\f5. Select Apply.\n",
      "\n",
      "Request item certification\n",
      "\n",
      "If you would like to certify your item but aren't authorized to do so, follow the steps\n",
      "\n",
      "below.\n",
      "\n",
      "1. Go to the workspace where the item you want to be certified is located, and then\n",
      "\n",
      "open the settings of that item.\n",
      "\n",
      "2. Expand the endorsement section. The Certified button is greyed out since you\n",
      "\n",
      "aren't authorized to certify content. Select the link about how to get your item\n",
      "\n",
      "certified.\n",
      "\n",
      "\f７ Note\n",
      "\n",
      "If you clicked the link above but got redirected back to this note, it means that\n",
      "\n",
      "your Power BI admin has not made any information available. In this case,\n",
      "\n",
      "contact the Power BI admin directly.\n",
      "\n",
      "Next steps\n",
      "\n",
      "Read more about endorsement\n",
      "\n",
      "Enable content certification (Power BI admins)\n",
      "\n",
      "Read more about dataset discoverability\n",
      "\n",
      "\fApply sensitivity labels to Fabric items\n",
      "\n",
      "Article • 05/23/2023\n",
      "\n",
      "） Important\n",
      "\n",
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "Sensitivity labels from Microsoft Purview Information Protection on items can guard\n",
      "\n",
      "your sensitive content against unauthorized data access and leakage. They're a key\n",
      "\n",
      "component in helping your organization meet its governance and compliance\n",
      "\n",
      "requirements. Labeling your data correctly with sensitivity labels ensures that only\n",
      "\n",
      "authorized people can access your data. This article shows you how to apply sensitivity\n",
      "\n",
      "labels to your Microsoft Fabric items.\n",
      "\n",
      "７ Note\n",
      "\n",
      "For information about applying sensitivity labels in Power BI Desktop, see Apply\n",
      "\n",
      "sensitivity labels in Power BI Desktop.\n",
      "\n",
      "Prerequisites\n",
      "\n",
      "Requirements needed to apply sensitivity labels to Fabric items:\n",
      "\n",
      "Power BI Pro or Premium Per User (PPU) license\n",
      "\n",
      "Edit permissions on the item you wish to label.\n",
      "\n",
      "７ Note\n",
      "\n",
      "If you can't apply a sensitivity label, or if the sensitivity label is greyed out in the\n",
      "\n",
      "sensitivity label menu, you may not have permissions to use the label. Contact your\n",
      "\n",
      "organization's tech support.\n",
      "\n",
      "Apply a label\n",
      "\n",
      "\fThere are two common ways of applying a sensitivity label to an item: from the flyout\n",
      "\n",
      "menu in the item header, and in the item settings.\n",
      "\n",
      "From the flyout menu - select the sensitivity indication in the header to display the\n",
      "\n",
      "flyout menu:\n",
      "\n",
      "In items settings - open the item's settings, find the sensitivity section, and then\n",
      "\n",
      "choose the desired label:\n",
      "\n",
      "\fNext steps\n",
      "\n",
      "Sensitivity label overview\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "print(rawDocs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Data/PDF/Fabric Get Started.pdf'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDocs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/PDF/Fabric Get Started.pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fabricGetStartedPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the source \n",
    "for doc in rawDocs:\n",
    "    doc.metadata['source'] = fabricGetStartedPath\n",
    "\n",
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "docs = textSplitter.split_documents(rawDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Fabric is currently in PREVIEW. This information relates to a prerelease\n",
      "\n",
      "product that may be substantially modified before it's released. Microsoft makes no\n",
      "\n",
      "warranties, expressed or implied, with respect to the information provided here.\n",
      "\n",
      "SaaS foundation\n",
      "\n",
      "Microsoft Fabric brings together new and existing components from Power BI, Azure\n",
      "\n",
      "Synapse, and Azure Data Explorer into a single integrated environment. These\n",
      "\n",
      "components are then presented in various customized user experiences.\n",
      "\n",
      "Fabric brings together experiences such as Data Engineering, Data Factory, Data Science,\n",
      "\n",
      "Data Warehouse, Real-Time Analytics, and Power BI onto a shared SaaS foundation. This\n",
      "\n",
      "integration provides the following advantages:\n",
      "\n",
      "\fAn extensive range of deeply integrated analytics in the industry.\n",
      "\n",
      "Shared experiences across experiences that are familiar and easy to learn.\n",
      "\n",
      "Developers can easily access and reuse all assets.\n",
      "\n",
      "A unified data lake that allows you to retain the data where it is while using your\n",
      "\n",
      "preferred analytics tools.\n",
      "\n",
      "Centralized administration and governance across all experiences.\n",
      "\n",
      "With the Microsoft Fabric SaaS experience, all the data and the services are seamlessly\n",
      "\n",
      "integrated. IT teams can centrally configure core enterprise capabilities and permissions\n",
      "\n",
      "are automatically applied across all the underlying services. Additionally, data sensitivity\n",
      "\n",
      "labels are inherited automatically across the items in the suite.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs),print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = QAGenerationChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qa \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun(docs[\u001b[39m55\u001b[39;49m]\u001b[39m.\u001b[39;49mpage_content)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chains\\qa_generation\\base.py:55\u001b[0m, in \u001b[0;36mQAGenerationChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     50\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     51\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     52\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, List]:\n\u001b[0;32m     54\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_splitter\u001b[39m.\u001b[39mcreate_documents([inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key]])\n\u001b[1;32m---> 55\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mgenerate(\n\u001b[0;32m     56\u001b[0m         [{\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m: d\u001b[39m.\u001b[39;49mpage_content} \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m docs], run_manager\u001b[39m=\u001b[39;49mrun_manager\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m     qa \u001b[39m=\u001b[39m [json\u001b[39m.\u001b[39mloads(res[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext) \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mgenerations]\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: qa}\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chains\\llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\base.py:143\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    137\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    138\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m    139\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    142\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\base.py:91\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m---> 91\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     92\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n\u001b[0;32m     93\u001b[0m generations \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results]\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\base.py:83\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[0;32m     79\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[0;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m     84\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m     85\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m     86\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[0;32m     88\u001b[0m     ]\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\base.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     79\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[0;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m---> 84\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     85\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m     86\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[0;32m     88\u001b[0m     ]\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\openai.py:320\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager)\u001b[0m\n\u001b[0;32m    316\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[0;32m    317\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[0;32m    318\u001b[0m     )\n\u001b[0;32m    319\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[1;32m--> 320\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    321\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\openai.py:281\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 281\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\concurrent\\futures\\_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\langchain\\chat_models\\openai.py:279\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sri.karan\\.conda\\envs\\langChain\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "qa = chain.run(docs[55].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
