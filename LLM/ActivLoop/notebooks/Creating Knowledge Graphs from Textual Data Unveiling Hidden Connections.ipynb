{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sri.karan\\.conda\\envs\\activeloop\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.15) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai,os\n",
    "load_dotenv(r'D:\\Git\\NLP\\LLM\\ActivLoop\\.env')\n",
    "openai_api_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "openai.api_base = os.getenv(\"OpenAiService\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =os.getenv(\"OpenAiVersion\")\n",
    "davincimodel= os.getenv(\"OpenAiDavinci\")\n",
    "active_loop_token=os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "embedding_model=os.getenv(\"OpenAiEmbedding\")\n",
    "chat_ai=os.getenv(\"ChatAI\")#\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In today's data-driven world, understanding the relationships between different pieces of information is crucial. Knowledge graphs have emerged as a powerful way to visualize and explore these connections, transforming unstructured text into a structured network of entities and their relationships. We will guide you through a simple workflow for creating a knowledge graph from textual data, making complex information more accessible and easier to understand.\n",
    "\n",
    "Workflow for Creating Knowledge Graphs from Textual Data\n",
    "Here’s what we are going to do in this project.\n",
    "\n",
    "https://learn.activeloop.ai/courses/take/langchain/multimedia/46317967-creating-knowledge-graphs-from-textual-data-unveiling-hidden-connections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graphs and Knowledge Bases: know the difference.\n",
    "Before diving deep into our main topic, it's important to have a clear understanding of the difference between Knowledge Graphs and Knowledge Bases.\n",
    "\n",
    "The terms \"knowledge graph\" and \"knowledge base\" are often used interchangeably, but they have subtle differences. Knowledge base (KB) refers to structured information that we have about a domain of interest. On the other hand, a knowledge graph is a knowledge base structured as a graph, where nodes represent entities and edges signify relations between those entities. For example, from the text “Fabio lives in Italy,” we can extract the relation triplet <Fabio, lives in, Italy>, where “Fabio” and “Italy” are entities, and “lives in” it’s their relation.\n",
    "\n",
    "A knowledge graph is a particular type of knowledge base. A knowledge base is not necessarily a knowledge graph.\n",
    "\n",
    "### Building a Knowledge Graph\n",
    "The process of building a knowledge graph usually consists of two sequential steps:\n",
    "\n",
    "1. Named Entity Recognition (NER): This step involves extracting entities from the text, which will eventually become the nodes of the knowledge graph.\n",
    "2. Relation Classification (RC): In this step, relations between entities are extracted, forming the edges of the knowledge graph.\n",
    "Then, the knowledge graph is commonly visualized using libraries such as pyvis .\n",
    "\n",
    "Typically the process of creating a knowledge base from the text can be enhanced by incorporating additional steps, such as:\n",
    "\n",
    "1. Entity Linking: This involves normalizing entities to the same entity, such as “Napoleon” and “Napoleon Bonapart.” This is usually done by linking them to a canonical source, like a Wikipedia page.\n",
    "2. Source Tracking: Keeping track of the origin of each relation, such as the article URL and text span. Keeping track of the sources allows us to gather insights into the reliability of the extracted information (e.g., a relation is accurate if it can be extracted from several sources considered accurate).\n",
    "In this project, we’ll do the Named Entity Recognition and Relation Classification tasks simultaneously with an appropriate prompt. This joint task is commonly called Relation Extraction (RE).\n",
    "\n",
    "### Building a Knowledge Graph with LangChain\n",
    "To demonstrate an example of using a prompt to extract relations from the text in LangChain, we can use the following  KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT prompt as a starting point. This prompt is designed to extract knowledge triples (subject, predicate, and object) from a given text input.\n",
    "\n",
    "This prompt can be used by the ConversationEntityMemory class from LangChain library, which is a way for chatbots to keep a memory of the past messages of a conversation by storing the relations extracted from the past messages. Memory classes will be explained in a later lesson. In this example, we use this prompt just to extract relations from texts without leveraging a memory class.\n",
    "\n",
    "Let's understand the structure of the KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT. This prompt is an instance of the PromptTemplate class with the input variable text. The template is a string that provides a few shot examples and instructions for the language model to follow when extracting knowledge triples from the input text. The following code requires the OPENAI_API_KEY key in the environment variable that stores your OpenAI API key. Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (Paris, is, capital)<|>(Paris, is, most populous city)<|>(Paris, is in, France)<|>(Eiffel Tower, is a, landmark)<|>(Eiffel Tower, is in, Paris)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
    "\n",
    "# Prompt template for knowledge triple extraction\n",
    "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
    "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
    "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
    "    \" them with your knowledge stored within your weights\"\n",
    "    \" as well as that stored in a knowledge graph.\"\n",
    "    \" Extract all of the knowledge triples from the text.\"\n",
    "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
    "    \" and an object. The subject is the entity being described,\"\n",
    "    \" the predicate is the property of the subject that is being\"\n",
    "    \" described, and the object is the value of the property.\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
    "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
    "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"I'm going to the store.\\n\\n\"\n",
    "    \"Output: NONE\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
    "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"{text}\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n",
    "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
    ")\n",
    "\n",
    "# Make sure to save your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Instantiate the OpenAI model\n",
    "llm = OpenAI(engine=davincimodel, temperature=0.9)\n",
    "\n",
    "# Create an LLMChain using the knowledge triple extraction prompt\n",
    "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
    "\n",
    "# Run the chain with the specified text\n",
    "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
    "triples = chain.run(text)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a networked intelligence helping a human track knowledge triples about all relevant people, things, concepts, etc. and integrating them with your knowledge stored within your weights as well as that stored in a knowledge graph. Extract all of the knowledge triples from the text. A knowledge triple is a clause that contains a subject, a predicate, and an object. The subject is the entity being described, the predicate is the property of the subject that is being described, and the object is the value of the property.\n",
      "\n",
      "EXAMPLE\n",
      "It's a state in the US. It's also the number 1 producer of gold in the US.\n",
      "\n",
      "Output: (Nevada, is a, state)<|>(Nevada, is in, US)<|>(Nevada, is the number 1 producer of, gold)\n",
      "END OF EXAMPLE\n",
      "\n",
      "EXAMPLE\n",
      "I'm going to the store.\n",
      "\n",
      "Output: NONE\n",
      "END OF EXAMPLE\n",
      "\n",
      "EXAMPLE\n",
      "Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\n",
      "Output: (Descartes, likes to drive, antique scooters)<|>(Descartes, plays, mandolin)\n",
      "END OF EXAMPLE\n",
      "\n",
      "EXAMPLE\n",
      "{text}Output:\n"
     ]
    }
   ],
   "source": [
    "print(KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT.template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous code, we used the prompt to extract relation triplets from text using few-shot examples. We'll then parse the generated triplets and collect them into a list.\n",
    "\n",
    "Here, triples_response will contain the knowledge triplets extracted from the text. We need to parse the response and collect the triplets into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' (Paris, is, capital)', '(Paris, is, most populous city)', '(Paris, is in, France)', '(Eiffel Tower, is, landmark)', '(Eiffel Tower, is in, Paris)']\n"
     ]
    }
   ],
   "source": [
    "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.split(delimiter)\n",
    "\n",
    "triples_list = parse_triples(triples)\n",
    "\n",
    "# Print the extracted relation triplets\n",
    "print(triples_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Visualization\n",
    "The NetworkX library is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. It provides various graph generators, random graphs, and synthetic networks, along with the benefits of Python's fast prototyping, ease of teaching, and multi-platform support.\n",
    "\n",
    "To visualize the extracted triplets as a knowledge graph, we’ll be using the pyvis library; To install the library, execute the following command. While it is preferable to install the latest version of the packages, it is worth noting that the codes in this lesson were written using version 0.3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# Create a NetworkX graph from the extracted relation triplets\n",
    "def create_graph_from_triplets(triplets):\n",
    "    G = nx.DiGraph()\n",
    "    for triplet in triplets:\n",
    "        subject, predicate, obj = triplet.strip().split(',')\n",
    "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
    "    return G\n",
    "\n",
    "# Convert the NetworkX graph to a PyVis network\n",
    "def nx_to_pyvis(networkx_graph):\n",
    "    pyvis_graph = Network(notebook=True)\n",
    "    for node in networkx_graph.nodes():\n",
    "        pyvis_graph.add_node(node)\n",
    "    for edge in networkx_graph.edges(data=True):\n",
    "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
    "    return pyvis_graph\n",
    "\n",
    "triplets = [t.strip() for t in triples_list if t.strip()]\n",
    "graph = create_graph_from_triplets(triplets)\n",
    "pyvis_network = nx_to_pyvis(graph)\n",
    "\n",
    "# Customize the appearance of the graph\n",
    "pyvis_network.toggle_hide_edges_on_drag(True)\n",
    "pyvis_network.toggle_physics(False)\n",
    "pyvis_network.set_edge_smooth('discrete')\n",
    "\n",
    "# Show the interactive knowledge graph visualization\n",
    "pyvis_network.show('knowledge_graph.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion\n",
    "Throughout this article, we've demonstrated a straightforward yet powerful workflow for creating knowledge graphs from textual data. We've transformed unstructured text into a structured network of entities and their relationships, making complex information more accessible and easier to understand.\n",
    "\n",
    "It's worth noting that LangChain offers the GraphIndexCreator class, which automates the extraction of relation triplets and is seamlessly integrated with question-answering chains. In future articles, we'll delve deeper into this powerful feature, showcasing its potential further to enhance your knowledge graph creation and analysis capabilities.\n",
    "\n",
    "The knowledge graph created through this workflow serves as a valuable tool for visualizing complex relationships and opens the door for further analysis, pattern recognition, and data-driven decision-making.\n",
    "\n",
    "Congrats in completing the second module of the course! You can now test your knowledge with the module quizzes. The next module will be about managing external knowledge in LLM-based applications using indexers and retrievers.\n",
    "\n",
    "https://medium.com/nlplanet/building-a-knowledge-base-from-texts-a-full-practical-example-8dbbffb912fa\n",
    "https://github.com/hwchase17/langchain/blob/master/langchain/indexes/prompts/knowledge_triplet_extraction.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
