{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sri.karan\\.conda\\envs\\activeloop\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai,os\n",
    "load_dotenv(r'D:\\Git\\NLP\\LLM\\ActivLoop\\.env')\n",
    "openai_api_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "openai.api_base = os.getenv(\"OpenAiService\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =os.getenv(\"OpenAiVersion\")\n",
    "davincimodel= os.getenv(\"OpenAiDavinci\")\n",
    "active_loop_token=os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "embedding_model=os.getenv(\"OpenAiEmbedding\")\n",
    "chat_ai=os.getenv(\"ChatAI\")#\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this lesson, we will explore the benefits of using GPT-4 and ChatGPT, focusing on their ability to maintain context in conversations. We will demonstrate how these advanced language models can remember conversation history and respond accordingly, making them ideal for chat applications. Additionally, we will briefly discuss the improvements in GPT-4, such as longer context length and better generalization. By the end of this lesson, you should be able to understand how GPT-4 and ChatGPT can be used for context-aware chat applications via the API, as opposed to just using the OpenAI ChatGPT webpage. \n",
    "\n",
    "As mentioned before, OpenAI's GPT-4 represents a significant advancement in the field of large language models. Among its many improvements are enhanced creativity, the ability to process visual input, and an extended contextual understanding. In the realm of conversational AI, both GPT-4 and ChatGPT use the Transformers architecture at their core and are fine-tuned to hold natural dialogue with a user. While the free version of ChatGPT relies on GPT-3, the premium offering, ChatGPT Plus, gives access to the more advanced GPT-4 model.\n",
    "\n",
    "The benefits of employing ChatGPT and GPT-4 in chat format are numerous. For instance, GPT-4's short-term memory capacity of 64,000 words greatly surpasses GPT-3.5's 8,000-word limit, enabling it to maintain context more effectively in prolonged conversations. Furthermore, GPT-4 is highly multilingual, accurately handling up to 26 languages, and boasts improved steering capabilities, allowing users to tailor responses with a custom \"personality.\"\n",
    "\n",
    "The new model is considerably safer to use, boasting a 40% increase in factual responses and an 82% reduction in disallowed content responses. It can also interpret images as a foundation for interaction. While this functionality has not yet been incorporated into ChatGPT, its potential to revolutionize context-aware chat applications is immense.\n",
    "\n",
    "##### Setting up the API\n",
    "To use GPT-4 or ChatGPT in your application, you must obtain API keys from OpenAI. You'll need to sign up for an account and submit a request to access the latest model. At the time of writing this lesson, there is a waitlist to get your hands on GPT-4. Then, set the OPENAI_API_KEY key in your environment variables so the LangChain library can access them.\n",
    "\n",
    "The following example demonstrates how to create a chatbot using the GPT-4 model from OpenAI. After importing the necessary classes, we declare a set of messages. It starts by setting the context for the model (SystemMessage) that it is an assistant, followed by the user’s query (HumanMessage), and finishes by defining a sample response from the AI model (AIMessage). Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\")\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the user posed the question about the capital of France, the model confidently answered with \"Paris.” Next up, we test if the model can leverage these discussions as a reference to delve further into details about the city without us explicitly mentioning the name (referring to Paris). The code below adds a new message which requires the model to understand and find the “city you just mentioned” reference from previous conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"I'd like to know more about the city you just mentioned.\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "llm = ChatOpenAI(engine=chat_ai)\n",
    "\n",
    "response = llm(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, Paris is the capital and largest city of France. It is located in the north-central part of the country, on the banks of the Seine River. Paris is known worldwide for its beautiful architecture, fashion, museums, art galleries, and cuisine. Some of the most popular tourist attractions in Paris include the Eiffel Tower, the Louvre Museum, Notre Dame Cathedral, the Champs-Elysees, and the Seine River. Paris is also known for its delightful cafes, restaurants, and bakeries, where visitors can enjoy the famous French cuisine and pastries.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model successfully extracted the information from previous conversations and explained more details about Paris. It shows that the chat models are capable of referring to the chat history and understanding the context.<br><br>\n",
    "\n",
    "To recap, the ChatOpenAI class is used to create a chat-based application that can handle user inputs and generate responses using the GPT-4 language model. The conversation is initiated with a series of messages, including system, human, and AI messages. The SystemMessage provides context for the conversation, while HumanMessage and AIMessage represent the user and the AI's messages, respectively.<br>\n",
    "\n",
    "The LangChain’s Chat API offers several advantages:<br><br>\n",
    "\n",
    "Context preservation: By maintaining a list of messages in the conversation, the API ensures that the context is preserved throughout the interaction. This allows the GPT-4 model to generate relevant and coherent responses based on the provided information.<br>\n",
    "Memory: The class’s message history acts as a short-term memory for the chatbot, allowing it to refer back to previous messages and provide more accurate and contextual responses.<br>\n",
    "Modularity: The combination of MessageTemplate and ChatOpenAI classes offers a modular approach to designing conversation applications. This makes it easier to develop, maintain, and extend the functionality of the chatbot.<br>\n",
    "Improved performance: GPT-4, as an advanced language model, is more adept at understanding complex prompts and generating better responses than its predecessors. It can handle tasks that require deeper reasoning and context awareness, which leads to a more engaging and useful conversation experience.<br>\n",
    "Flexibility: The Chat API can be adapted to different domains and tasks, making it a versatile solution for various chatbot applications. In this example, the chatbot specializes in French culture but could be easily modified to focus on other subjects or industries. Moreover, as newer and more powerful language models become available, the API can be updated to utilize those models, allowing for continuous improvements in chatbot capabilities.<br><br>\n",
    "### Conclusion\n",
    "In this lesson, we learned that GPT-4 boasts remarkable advancements in context length and generalization, paving the way for more sophisticated language processing. By accommodating a more extensive context, GPT-4 can generate lengthier text pieces, analyze more massive documents, and engage in longer conversations without compromising the context's integrity.\n",
    "\n",
    "ChatGPT and GPT-4 models are tailor-made for conversational interfaces, which require input to be formatted in a specific chat-like transcript format. This format empowers the models to retain conversation history and furnish contextually relevant responses. This attribute is especially advantageous for multi-turn conversations and can also prove useful in non-chat scenarios.\n",
    "\n",
    "These potent models have diverse applications, including customer support chatbots that manage intricate inquiries and dispense pertinent responses based on previous interactions. They can also function as virtual personal assistants that preserve context across various tasks and requests. They also serve as natural language interfaces for databases and search engines, enabling them to better understand user queries and provide more accurate results.\n",
    "\n",
    "In the next lesson, you’ll do the first project of the course, that is a news summarizer leveraging LangChain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
