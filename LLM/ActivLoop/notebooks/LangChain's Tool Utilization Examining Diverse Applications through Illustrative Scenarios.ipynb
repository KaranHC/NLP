{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai,os\n",
    "load_dotenv(r'D:\\Git\\NLP\\LLM\\ActivLoop\\.env')\n",
    "openai_api_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "openai.api_base = os.getenv(\"OpenAiService\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =os.getenv(\"OpenAiVersion\")\n",
    "davincimodel= os.getenv(\"OpenAiDavinci\")\n",
    "active_loop_token=os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "embedding_model=os.getenv(\"OpenAiEmbedding\")\n",
    "chat_ai=os.getenv(\"ChatAI\")#\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Tools are modular, reusable components meticulously designed to accomplish specific tasks or provide answers to distinct types of questions. By integrating these tools seamlessly into the system, users can effortlessly tap into a diverse range of functionalities and information sources to tackle challenges and generate meaningful responses. In this lesson, we will explore the various Tools in LangChain, uncovering their unique capabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notable examples of tools in LangChain, without getting into technical details, are:\n",
    "\n",
    "1. Google Search: This tool uses the Google Search API to fetch relevant information from the web, which can be used to answer queries related to current events, facts, or any topic where a quick search can provide accurate results.\n",
    "\n",
    "2. Requests: This tool employs the popular Python library \"requests\" to interact with web services, access APIs, or obtain data from different online sources. It can be particularly useful for gathering structured data or specific information from a web service.\n",
    "3. Python REPL: The Python REPL (Read-Eval-Print Loop) tool allows users to execute Python code on-the-fly to perform calculations, manipulate data, or test algorithms. It serves as an interactive programming environment within the LangChain system.\n",
    "4. Wikipedia: The Wikipedia tool leverages the Wikipedia API to search and retrieve relevant articles, summaries, or specific information from the vast repository of knowledge on the Wikipedia platform.\n",
    "5. Wolfram Alpha: With this tool, users can tap into the powerful computational knowledge engine of Wolfram Alpha to answer complex questions, perform advanced calculations, or generate visual representations of data.<br><br>\n",
    "LangChain Agents and Toolkits\n",
    "\n",
    "\n",
    "In LangChain, an Agent is a bot that acts using natural language instructions and can use tools to answer its queries. Based on user input, it is also used to determine which actions to take and in what order. An action can either be using a tool (such as a search engine or a calculator) and processing its output or returning a response to the user. Agents are powerful when used correctly, as they can dynamically call chains based on user input.<br>\n",
    "\n",
    "An agent has access to a suite of tools and can decide which of these tools to call, depending on the user input. Tools are functions that perform specific duties. To create an agent in LangChain, you can use the initialize_agent function along with the load_tools function to prepare the tools the agent can use. <br>\n",
    "\n",
    "For example, you can create a simple agent using the following code. It can use the SerpApi service to fetch Google search results or the Python requests wrapper when required. Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(engine=davincimodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = load_tools(['serpapi', 'requests_all'], llm=llm, serpapi_api_key=os.getenv(\"SERPAPI_API_KEY\"))\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m this might be a company or a product\n",
      "Action: Search\n",
      "Action Input: midjourney\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMidjourney is a generative artificial intelligence program and service created and hosted by San Francisco-based independent research lab Midjourney, Inc. Midjourney generates images from natural language descriptions, called \"prompts\", similar to OpenAI's DALL-E and Stable Diffusion.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m this is the final answer\n",
      "Final Answer: Midjourney is a generative artificial intelligence program and service created and hosted by San Francisco-based independent research lab Midjourney, Inc.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Midjourney is a generative artificial intelligence program and service created and hosted by San Francisco-based independent research lab Midjourney, Inc.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"tell me what is midjourney?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent will then use the tool to look for an answer to the query. We’ll see some output examples later in this lesson.\n",
    "\n",
    "### Google-Search\n",
    "LLMs inherently possess knowledge only up to the point at which they were trained, leaving them unaware of any information beyond that timeframe. Integrating search engines as tools within the LangChain system presents a significant advantage. The LangChain library provides a Google Search API wrapper that you can use within your project. You can use this wrapper as a standalone utility or as a tool within an agent.\n",
    "\n",
    "First, make sure you have an API Key and Custom Search Engine ID for the Google Search API. If you don’t already have a Custom Search Engine ID, the following tutorial is a helpful guide for generating one.\n",
    "\n",
    "https://help.elfsight.com/article/331-how-to-get-search-engine-id<br>\n",
    "https://support.google.com/googleapi/answer/6158862?hl=en<br>\n",
    "\n",
    "https://serpapi.com/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-OPENAI-API-KEY>\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR-GOOGLE-API-KEY>\"\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"<YOUR-GOOGLE-CSE-ID>\"\n",
    "\n",
    "# As a standalone utility:\n",
    "from langchain. utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "search.results(\"What is the capital of Spain?\", 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the LangChain library, using the available tools requires some necessary steps to be taken. First, you need to initialize an agent, which is the central manager for effectively using these tools. Then, we need to define the language model that we want the agent to use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(engine=davincimodel, temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can initialize an agent and load the google-search tool for it to use. The agent will load the search results and provide them to the llm to answer our question. The ZERO_SHOT_REACT_DESCRIPTION type gives the freedom to choose any of the defined tools to provide context for the model based on their description. (You can use different agent types, read more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, load_tools, AgentType\n",
    "\n",
    "tools = load_tools([\"google-search\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "print( agent(\"What is the national drink in Spain?\") )Copy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests\n",
    "The internet is an extensive source of information that Large Language Models cannot access directly. LangChain offers a convenient wrapper built around the Python Requests module to facilitate seamless interaction between LLMs and this wealth of information. This wrapper accepts a URL as an input and efficiently retrieves data from the specified URL, allowing LLMs to obtain and process web-based content effortlessly.\n",
    "\n",
    "In this example, we’ll set up a  fake RESTful backend using mockapi.io. To do it, follow these steps:\n",
    "\n",
    "1. Go to mockapi.io and sign up for a free account.\n",
    "2. After signing up, log in to your account.\n",
    "3. Click on \"New Project\" (the \"+\" icon) and give your project a name. You don't need to fill in any optional fields.\n",
    "4. Once the project is created, click on it to view your unique API endpoint.\n",
    "5. Click on \"New Resource\" to create a new resource for your API. For example, if you want to create an endpoint for users, you can name the resource \"users.”\n",
    "6. Define the schema for your resource. For instance, if you want each user to have an id, name, and email, you can use the following schema:\n",
    "\n",
    "{\n",
    "    \"id\": \"integer\",\n",
    "    \"name\": \"string\",\n",
    "    \"email\": \"string\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the \"Create\" button to create the resource with the defined schema.\n",
    "\n",
    "This fake backend will have an endpoint to retrieve information about fake users stored in the backend. A dictionary will represent each user. For instance:\n",
    "\n",
    "{\n",
    "    \"id\": \"1\",\n",
    "    \"name\": \"John Doe\",\n",
    "    \"email\": \"john.doe@example.com\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the LangChain tools to interact with our fake RESTful backend. First, import the necessary libraries and initialize the agent with the desired tools. Then, ask the agent to do an HTTP call at “https://644696c1ee791e1e2903b0bb.mockapi.io/user”: this is the address of our specific mockapi instance, where you should find 30 users. If you want to try your mockapi instance, then replace the address with “https://<YOUR-MOCKAPI-SERVER-ID>.mockapi.io/user”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = load_tools([\"requests_all\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "response = agent.run(\"Get the list of users at https://644696c1ee791e1e2903b0bb.mockapi.io/user and tell me the total number of users\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entering new AgentExecutor chain...\n",
    "\n",
    "I need to get the content from this URL\n",
    "Action: requests_get\n",
    "Action Input: https://644696c1ee791e1e2903b0bb.mockapi.io/user\n",
    "\n",
    "Observation:\n",
    "\n",
    "[{\"createdAt\": \"2023-04-24T07:55:47.634Z\", \"name\": \"Mr. Kelly Balistreri\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1244.jpg\", \"id\": \"1\"},{\"createdAt\": \"2023-04-24T03:54:44.108Z\", \"name\": \"Bradley Cronin\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/615.jpg\", \"id\": \"2\"},{\"createdAt\": \"2023-04-24T14:32:29.991Z\" , \"name\": \"Jennifer Block Sr.\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/105.jpg\", \"id\": \"3\"},\n",
    "\n",
    "[…]\n",
    "\n",
    "{\"createdAt\": \"2023-04-24T06:10:38.771Z\", \"name\": \"Paula Kshlerin\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1145.jpg\", \"id\": \"28\"},{\"createdAt\": \"2023-04-24T03:15:33.343Z\", \"name\": \"Roberto Blanda\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/575.jpg\", \"id\": \"29\"},{\"createdAt\": \"2023-04-23T18:20:58.632Z\", \"name\":  \"Mr. Lisa Erdman\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1172.jpg\", \"id\": \"30\"}]\n",
    "\n",
    "Thought:\n",
    "\n",
    "I now know the list of users\n",
    "Final Answer: The list of users from the URL https://644696c1ee791e1e2903b0bb.mockapi.io/user is: [{\"createdAt\": \"2023-04-24T07:55:47.634Z\", \"name\": \"Mr. Kelly Balistreri\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/1244.jpg\", \"id\": \"1\"},{\"createdAt\": \"2023-04-24T03:54:44.108Z\", \"name\": \"Bradley Cronin\", \"avatar\": \"https://cloudflare-ipfs.com/ipfs/Qmd3W5DuhgHirLHGVixi6V76LhCkZUz6pnFt5AJBiyvHye/avatar/615.jpg\", \"id\": \"2\"},{\"createdAt\": \"2023-04-24T14:32:29.991Z\", \"name\":\"\n",
    "\n",
    "[…]\n",
    "\n",
    "Thought:\n",
    "\n",
    "I now know the final answer\n",
    "Final Answer: There are 30 users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in this example, the agent, initialized with the Request tool and the OpenAI language model, processes the given prompt. It identifies the need to fetch data from the provided URL using a GET request, which is facilitated by the tool of the request. Upon retrieving the user data, the agent analyzes the number of users and returns the result, completing the task.\n",
    "\n",
    "### Python-REPL\n",
    "Another tool feature in LangChain is the Python REPL tool, which allows you to execute Python code generated by the language model. This can be useful for complex calculations where the language model generates code to calculate the answer since LLMs are not good at solving algorithmic and math problems. \n",
    "\n",
    "Here’s an example of  Python-REPL tool usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to create a list of random strings, sort them, and print them out\n",
      "Action: Python_REPL\n",
      "Action Input: import random\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to create a list of random strings, sort them, and print them out\n",
      "Action: Python_REPL\n",
      "Action Input: random_strings = [''.join(random.choices(string.ascii_lowercase, k=4)) for i in range(30)]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNameError(\"name 'string' is not defined\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to create a list of random strings, sort them, and print them out\n",
      "Action: Python_REPL\n",
      "Action Input: import string\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to create a list of random strings, sort them, and print them out\n",
      "Action: Python_REPL\n",
      "Action Input: random_strings = [''.join(random.choices(string.ascii_lowercase, k=4)) for i in range(30)]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to sort the list\n",
      "Action: Python_REPL\n",
      "Action Input: random_strings.sort()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to print the list\n",
      "Action: Python_REPL\n",
      "Action Input: print(random_strings)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['amwg', 'boxn', 'ciny', 'coso', 'dfui', 'guoa', 'gzul', 'htqg', 'isxr', 'iweo', 'lrzx', 'mclp', 'mpxn', 'nkuh', 'ohee', 'plpk', 'prmc', 'qvgt', 'raqp', 'shvw', 'skvr', 'twyv', 'ucpm', 'vcds', 'vozp', 'vtkg', 'xpyp', 'xyok', 'xzmw', 'xzvx']\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: ['amwg', 'boxn', 'ciny', 'coso', 'dfui', 'guoa', 'gzul', 'htqg', 'isxr', 'iweo', 'lrzx', 'mclp', 'mpxn', 'nkuh', 'ohee', 'plpk', 'prmc', 'qvgt', 'raqp', 'shvw', 'skvr', 'twyv', 'ucpm', 'vcds', 'vozp', 'vtkg', 'xpyp', 'xyok', 'xzmw', 'xzvx']\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "['amwg', 'boxn', 'ciny', 'coso', 'dfui', 'guoa', 'gzul', 'htqg', 'isxr', 'iweo', 'lrzx', 'mclp', 'mpxn', 'nkuh', 'ohee', 'plpk', 'prmc', 'qvgt', 'raqp', 'shvw', 'skvr', 'twyv', 'ucpm', 'vcds', 'vozp', 'vtkg', 'xpyp', 'xyok', 'xzmw', 'xzvx']\n"
     ]
    }
   ],
   "source": [
    "tools = load_tools([\"python_repl\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "print( agent.run(\"Create a list of random strings containing 4 letters, list should contain 30 examples, and sort the list alphabetically\") )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia\n",
    "The Wikipedia API tool in LangChain is a powerful tool that allows language models to interact with the Wikipedia API to fetch information and use it to answer questions. Be aware that you need to install the Wikipedia python package using the pip install Wikipedia command. The codes are tested using the 1.4.0 version. However, use the latest version of the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m He is a prophet\n",
      "Action: Python_REPL\n",
      "Action Input: print(\"Nostradamus is a French prophet who lived in the 16th century. He is known for his book Les Propheties, which contains predictions about future events.\")\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNostradamus is a French prophet who lived in the 16th century. He is known for his book Les Propheties, which contains predictions about future events.\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Nostradamus is a French prophet who lived in the 16th century. He is known for his book Les Propheties, which contains predictions about future events.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Nostradamus is a French prophet who lived in the 16th century. He is known for his book Les Propheties, which contains predictions about future events.\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "tools = load_tools([\"wikipedia\"])\n",
    "\n",
    "print( agent.run(\"What is Nostradamus know for\") )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wolfram-Alpha\n",
    "In LangChain, you can integrate Wolfram Alpha by using the WolframAlphaAPIWrapper utility. First, you need to set up a Wolfram Alpha developer account and get your APP ID. \n",
    "\n",
    "Wolfram|Alpha APIs: Computational Knowledge Integration\n",
    "Easily add top-of-the-line computational knowledge into your applications with Wolfram|Alpha APIs. Options from free to pre-built and custom solutions.\n",
    "\n",
    "\n",
    "products.wolframalpha.com\n",
    "\n",
    "Wolfram|Alpha APIs: Computational Knowledge Integration\n",
    "Then, install the Wolfram Alpha Python library with pip install Wolframalpha.\n",
    "After that, you can set the Wolfram Alpha APP ID as an environment variable in your code:\n",
    "https://products.wolframalpha.com/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"your_app_id\"\n",
    "\n",
    "from langchain. utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "\n",
    "wolfram = WolframAlphaAPIWrapper()\n",
    "result = wolfram.run(\"What is 2x+5 = -3x + 7?\")\n",
    "print(result)  # Output: 'x = 2/5'Copy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the WolframAlphaAPIWrapper from the LangChain library, this code solves the algebraic equation. Let’s observe the WolframAlpha as a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wolfram-alpha\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "print( agent.run(\"How many days until the next Solar eclipse\") )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Showcase of Resourceful Collaboration\n",
    "Agents have the capability to employ a variety of tools in order to provide comprehensive and accurate responses to complex inquiries. These agents are better equipped to deliver well-rounded solutions by integrating resources such as Wikipedia and Wolfram-Alpha. Here’s an example of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the current F1 champion is\n",
      "Action: Wikipedia\n",
      "Action Input: \"List of Formula One World Drivers' Champions\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: List of Formula One World Drivers' Champions\n",
      "Summary: Formula One, abbreviated to F1, is the highest class of open-wheeled auto racing defined by the Fédération Internationale de l'Automobile (FIA), motorsport's world governing body. The \"formula\" in the name refers to a set of rules to which all participants and cars must conform. The Formula One World Championship season consists of a series of races, known as Grands Prix, held usually on purpose-built circuits, and in a few cases on closed city streets. The World Drivers' Championship is presented by the FIA to the most successful Formula One driver over the course of the season through a points system based on individual Grand Prix results. The World Championship is won when it is no longer mathematically possible for another competitor to overtake their points total regardless of the outcome of the remaining races, although it is not officially awarded until the FIA Prize Giving Ceremony held in various cities following the conclusion of the season.Michael Schumacher and Lewis Hamilton hold the record for the most World Drivers' Championships, both having won the title on seven occasions. Juan Manuel Fangio is third with five titles. Schumacher also holds the record for the most consecutive drivers' titles with five between the 2000 and the 2004 seasons. Nigel Mansell holds the record of competing in the highest number of seasons before winning the World Championship, entering Formula One in 1980 and achieving the title in 1992, a span of 13 seasons. Nico Rosberg has the highest number of Grand Prix starts before winning his first title, a period of 206 Grands Prix between the 2006 Bahrain and the 2016 Abu Dhabi Grand Prix. Sebastian Vettel is the youngest winner of the World Drivers' Championship; he was 23 years and 134 days old when he won the 2010 championship. Fangio is the oldest winner of the World Drivers' Championship; he was 46 years and 41 days old when he won the 1957 title.As of the 2022 season, out of the 770 drivers who have started a Formula One Grand Prix, the 73 titles awarded have been won by a total of 34 different drivers. The first Formula One World Drivers' Champion was Giuseppe Farina in the 1950 championship and the current title holder is Max Verstappen in the 2022 season. The title has been won by drivers from the United Kingdom 20 times between 10 drivers, more than any other nation, followed by Brazil, Finland and Germany with three drivers each. The title has been won by drivers from Scuderia Ferrari 15 times between 9 drivers, more than any other team, followed by McLaren with 12 titles between 7 drivers. The Drivers' Championship has been won in the final race of the season 30 times in the 72 seasons it has been awarded. Schumacher holds the record of earning the championship with most Grands Prix left to run in a season with six when he won the 2002 title at that year's French Grand Prix. Due to the points system, on two occasions (John Surtees in the 1964 season and Ayrton Senna in the 1988 season) a world champion scored less points overall than a driver who finished second in the championship.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of Formula One World Constructors' Champions\n",
      "Summary: Formula One, abbreviated to F1, is the highest class of open-wheeled auto racing defined by the Fédération Internationale de l'Automobile (FIA), motorsport's world governing body. The \"formula\" in the name refers to a set of rules to which all participants and cars must conform. The F1 World Championship season consists of a series of races, known as Grands Prix, held usually on purpose-built circuits, and in a few cases on closed city streets. The World Constructors' Championship is presented by the FIA to the most successful F1 constructor over the course of the season through a points system based on individual Grand Prix results. Constructors' Championship points are calculated by adding points scored in each race by any driver for that constructor. From the inaugural se\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Max Verstappen\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Max Verstappen'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tools = load_tools([\"wolfram-alpha\", \"wikipedia\"], llm=llm)\n",
    "tools = load_tools([\"wikipedia\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "\t\t\n",
    "        tools,\n",
    "\t\tllm,\n",
    "\t\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\t\tverbose=True\n",
    "\t)\n",
    "\n",
    "# agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")\n",
    "agent.run(\"Who is the 2022 F1 champion?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "LangChain agents successfully bring together various tools, like Wikipedia and Wolfram-Alpha, to create a seamless knowledge integration experience. By combining the strengths of these resources, the agents are able to provide clear, accurate, and detailed answers to more complex questions.\n",
    "\n",
    "Defining custom tools involves creating new classes, functions, or modules that serve specific purposes within your language processing pipeline. These custom tools can enhance or modify existing language processing capabilities provided by the LangChain library or create entirely new functionalities tailored to your specific needs. More on Defining Custom tools will be covered in lessons to come. Happy Learning!\n",
    "\n",
    "In the next lesson, we’ll build a bot able to refine paragraphs of articles by looking for additional context information online and adding it to that paragraph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
