{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sri.karan\\.conda\\envs\\activeloop\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.19) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai,os\n",
    "load_dotenv(r'D:\\Git\\NLP\\LLM\\ActivLoop\\.env')\n",
    "openai_api_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "openai.api_base = os.getenv(\"OpenAiService\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =os.getenv(\"OpenAiVersion\")\n",
    "davincimodel= os.getenv(\"OpenAiDavinci\")\n",
    "active_loop_token=os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "embedding_model=os.getenv(\"OpenAiEmbedding\")\n",
    "chat_ai=os.getenv(\"ChatAI\")#\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This discussion begins a fascinating journey through the latest LangChain efforts. A paradigm shift from traditional frameworks is represented by a novel project - \"CAMEL,” where we breathe life into unique agents equipped with distinct personalities and set them to work together in a harmonious ecosystem. \n",
    "\n",
    "Simultaneously, we’ll present the innovative dimensions of the 'Generative Agents' project. These agents don't merely simulate human tasks but encapsulate the essence of human behavior in a dynamic, interactive sandbox environment, creating a spectrum of intricate social interactions. The concept, a fusion of LLMs with computational agents, is a stepping stone toward enabling compelling simulations of human behavior.\n",
    "\n",
    "### The Agent Simulation projects in LangChain\n",
    "The Agent simulation projects in LangChain refer to a unique subset of AI research where autonomous Agents are created with distinct personalities or roles. \n",
    "\n",
    "These agents are designed to interact with each other autonomously, without the need for constant human supervision or intervention. They are not just tools utilized by a higher-level agent or human, but they are viewed as equal participants in the conversation or task. \n",
    "\n",
    "This novel approach to interaction differs from prior LangChain implementations and allows for the emergence of unique and compelling behaviors as the agents communicate with each other.\n",
    "\n",
    "For instance, the agents can have different tools or capabilities available to them. They can be specialized around those tools: one agent might be equipped with tools for coding, while another could be optimized for normal interactions. This allows for the potential of a \"stacking\" effect, where different agents are responsible for different aspects of a task, creating a more complex and dynamic simulation environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.langchain.dev/agents-round/<br>\n",
    "Agent Simulation projects, such as CAMEL and Generative Agents, introduce innovative simulation environments and incorporate a type of long-term memory that adapts based on events. Their distinctiveness comes from their environments and memory mechanisms.\n",
    "\n",
    "The role of agents in this context is to act as reasoning engines connected to tools and memory. Tools serve to link the LLM with other data or computation sources, such as search engines, APIs, and other data stores.\n",
    "They address the limitation of the LLM's fixed knowledge base by fetching up-to-date data and providing the capacity to perform actions.\n",
    "\n",
    "On the other hand, memory allows the agent to recall past interactions. This can aid in providing context and informing the decision-making process based on past experiences.\n",
    "\n",
    "The LangChain Agent, following the Reasoning and Acting (ReAct) framework proposed by Yao et al. in 2022, operates in a loop until a stopping criterion is met. It reflects a shift from traditional task execution to a more responsive and interactive model.\n",
    "\n",
    "This trend demonstrates a significant advance in the capabilities of LLMs as they transition from mere language processors to Agents that can reason, learn, and act.\n",
    "\n",
    "### What is the CAMEL project?\n",
    "The CAMEL paper \n",
    "\n",
    "This paper introduces a new concept in the field of artificial intelligence and conversational language models, focusing on the development of autonomous \"communicative agents\". Current models often depend heavily on human input, which can be demanding and time-consuming. The authors propose a novel framework called 'role-playing' that aims to address this issue, improving the autonomy and cooperation of the chat agents.\n",
    "\n",
    "ghli.org\n",
    "ghli.org\n",
    "\n",
    "In this framework, agents use 'inception prompting' to guide their interactions towards completing tasks while aligning with the initial human intent. This shift towards autonomy in agents may significantly reduce the need for human supervision.\n",
    "\n",
    "The authors present an open-source library with various tools, prompts, and agents that can aid future research in cooperative AI, multi-agent systems, and more. Through role-playing, the team is able to generate vast conversational datasets, enabling an in-depth study of chat agent behavior and capabilities.\n",
    "\n",
    "The aim of the CAMEL project is to enhance the ability of chat agents to understand and respond more effectively to human language, contributing to the development of more advanced and efficient language models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure illustrates the role-playing framework in the context of creating a trading bot for the stock market. Here's how it works:\n",
    "\n",
    "1. The process begins with a human user having an idea they want to accomplish. In this case, the idea is to develop a trading bot for the stock market.\n",
    "2. This task involves two AI agents, each with different roles. One agent acts as an AI assistant, equipped with Python programming skills, and the other as an AI user with stock trading expertise.\n",
    "3. A 'task specifier agent' refines the general idea into a well-defined task that the assistant can work on to make the task more specific. This could be something like writing a specific piece of code or performing a certain analysis on stock market data.\n",
    "4. Once the task is specified, the AI user and the AI assistant start interacting. They communicate with each other through chat, following instructions, and collaborating to solve the specified task.<br>\n",
    "This shows how the role-playing framework allows different AI agents to work together autonomously, just like a team of humans might do, to solve a complex task without needing constant human intervention. However, achieving this autonomy is not without challenges, including hallucinations, conversation deviation, role flipping, and termination conditions.\n",
    "\n",
    "Evaluating the task completion capabilities of the role-playing framework is challenging due to the vast scale and task diversity, requiring the involvement of numerous domain experts.\n",
    "\n",
    "For future work, the researchers propose extending the role-playing setting to include more than two chat agents. They also suggest having agents compete against each other, potentially discovering more insights into the interaction dynamics of LLM agents.\n",
    "\n",
    "The CAMEL project in LangChain\n",
    "In LangChain documentation, you can see the illustrated example  of a stock trading bot using the interaction between two AI agents - a stock trader and a Python programmer:<br>\n",
    "https://python.langchain.com/docs/use_cases/agent_simulations/camel_role_playing.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interaction shows how tasks are broken down into smaller, manageable steps that each agent can understand and execute, thereby completing the main task.\n",
    "\n",
    "Throughout the conversation, the user-agent (stock trader) provided instructions that were gradually refined into a more technical language by the assistant agent (Python programmer). This process demonstrates the system's ability to understand, translate, and execute task-related instructions effectively. Also, the agent's ability to accept the input, process it, and generate a detailed solution, emphasizes the feasibility of role assignment and context adaptation in cooperative AI systems. It also illustrates the significance of iterative feedback loops in achieving the goal.\n",
    "\n",
    "From another perspective, this interaction illustrates how agents can autonomously make decisions based on predefined conditions and parameters. For example, the assistant agent was able to compute moving averages, generate trading signals, and create new data frames to execute trading strategies, all based on the user agent's instruction.\n",
    "\n",
    "This scenario reveals the potential of autonomous, cooperative AI systems in solving complex, real-world problems, role definition, and iterative collaboration between agents in achieving results.\n",
    "\n",
    "##### What are Generative Agents?\n",
    "Generative Agents in LangChain are computational constructs designed to simulate believable human behavior. This design is inspired by the research paper 'Generative Agents: Interactive Simulacra of Human Behavior.’\n",
    "\n",
    "The Generative Agents project introduces a novel approach to using LLMs as Agents, focusing primarily on creating a unique simulation environment and a complex long-term memory system for them. \n",
    "\n",
    "The simulation environment in the Generative Agents project comprises 25 different agents, creating an intricate and highly specific setting. \n",
    "\n",
    "Despite its complexity, the long-term memory developed for the agents is truly innovative and worth examining in more depth: Generative Agents possess an extended memory stored as a single stream. The memory is composed of 'Observations', which are derived from interactions and dialogues within the virtual world concerning themselves or others, and 'Reflections', which are core memories that have been summarized and resurfaced.\n",
    "\n",
    "The long-term memory system of these agents consists of several components:\n",
    "\n",
    "1. Importance reflection steps: This component assigns an importance score to each observation. The score serves as a reference during retrieval, allowing the system to fetch significant memories and disregard less relevant ones.\n",
    "2. Reflection steps: These steps allow the agent to \"pause\" and evaluate the generalizations it has learned. These reflections can then be retrieved along with normal memories. This process aids in condensing information and spotting patterns in recent memories.\n",
    "3. A retriever that combines recency, relevancy, and importance: This advanced memory retriever surfaces memories that are similar to the current situation, occurred recently, and hold a high importance score. This model of memory retrieval closely mirrors how humans recall memories.\n",
    "In this framework, the agents interact with their environment and record their experiences in a time-weighted Memory object supported by a LangChain Retriever. This memory object differs from the conventional LangChain Chat memory in its formation and recall capabilities.<br>\n",
    "\n",
    "Regarding how these innovations were integrated into LangChain, the retriever logic was found to be generalizable. It was therefore added as a TimeWeightedVectorStoreRetriever, which also records the last time the memory was accessed.\n",
    "\n",
    "When an agent responds to an observation, it generates queries for the retriever. These queries fetch relevant documents based on their salience, recency, and importance. The agent then summarizes the retrieved information and updates the 'last accessed time' for the used documents.\n",
    "\n",
    "The Generative Agents project represents significant progress in the development of intelligent agents, introducing an innovative memory system that improves retrieval processes and enables agents to make better, more informed decisions. The partial adoption of these features into LangChain signifies their potential value and application in LLM projects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Agents is a project aimed at creating believable simulations of human behavior for interactive applications. The project represents these generative agents as computational software agents that emulate human activities in a simulated environment akin to the virtual world in The Sims.\n",
    "\n",
    "The generative agents are created to perform various activities like waking up, cooking breakfast, going to work, painting (for artist agents), writing (for author agents), forming opinions, noticing each other, and initiating conversations.  They remember and reflect on past days and use these memories to plan for the next day!\n",
    "\n",
    "Users can observe and even intervene in the agents' activities in this virtual environment.\n",
    "\n",
    "For example, an agent might decide to throw a Valentine's Day party, autonomously spread invitations to the party over two days, make new acquaintances, ask other agents out on dates to the party, and coordinate to show up for the party together at the right time.\n",
    "\n",
    "This architecture combines a large language model with mechanisms for synthesizing and retrieving relevant information, allowing for conditional behavior based on past experiences. The core of this architecture is the 'Memory Stream,’ a database that maintains a comprehensive record of an agent’s experiences. It retrieves and synthesizes the most relevant memories to guide the agent's actions, contributing to more consistent and coherent behavior.\n",
    "\n",
    "This project fuses large language models with computational, interactive agents, introducing architectural and interaction patterns that facilitate such believable simulations. The project could offer new insights and capabilities for interactive applications, immersive environments, rehearsal spaces for interpersonal communication, and prototyping tools.\n",
    "\n",
    "In the next lesson, we’ll create an LLM-based agent able to create small analysis report by planning a series of queries from a starting goal.\n",
    "\n",
    "Additional Resources:\n",
    "\n",
    "\n",
    "https://www.camel-ai.org/<br>\n",
    "https://python.langchain.com/docs/use_cases/agent_simulations/camel_role_playing.html<br>\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/agent_simulations/characters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
