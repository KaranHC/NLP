{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sri.karan\\.conda\\envs\\activeloop\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai,os\n",
    "load_dotenv(r'D:\\Git\\NLP\\LLM\\ActivLoop\\.env')\n",
    "openai_api_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "openai.api_base = os.getenv(\"OpenAiService\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =os.getenv(\"OpenAiVersion\")\n",
    "davincimodel= os.getenv(\"OpenAiDavinci\")\n",
    "active_loop_token=os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "embedding_model=os.getenv(\"OpenAiEmbedding\")\n",
    "chat_ai=os.getenv(\"ChatAI\")#\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In today's fast-paced world, it's essential to stay updated with the latest news and information. However, going through multiple news articles can be time-consuming. To help you save time and get a quick overview of the important points, let’s develop a News Articles Summarizer application using ChatGPT and LangChain. With this powerful tool, we can scrape online articles, extract their titles and text, and generate concise summaries. Within this lesson, we will walk you through the workflow of constructing a summarizer. We will employ the concepts we discussed in earlier lessons, demonstrating their application in a real-world scenario.\n",
    "\n",
    "Workflow for Building a News Articles Summarizer\n",
    "Here’s what we are going to do in this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the steps described in more detail:<br><br>\n",
    "\n",
    "Install required libraries: To get started, ensure you have the necessary libraries installed: requests, newspaper3k, and langchain.<br>\n",
    "Scrape articles: Use the requests library to scrape the content of the target news articles from their respective URLs.<br>\n",
    "Extract titles and text: Employ the newspaper library to parse the scraped HTML and extract the titles and text of the articles.<br>\n",
    "Preprocess the text: Clean and preprocess the extracted texts to make them suitable for input to ChatGPT.\n",
    "Generate summaries: Utilize ChatGPT to summarize the extracted articles' text concisely.<br>\n",
    "Output the results: Present the summaries along with the original titles, allowing users to grasp the main points of each article quickly.<br>\n",
    "By following this workflow, you can create an efficient News Articles Summarizer that leverages ChatGPT to provide valuable insights in a time-saving manner. Stay informed without spending hours reading through lengthy articles, and enjoy the benefits of AI-powered summarization.<br><br>\n",
    "\n",
    "Before you start, obtain your OpenAI API key from the OpenAI website. You need to have an account and be granted access to the API. After logging in, navigate to the API keys section and copy your API key.<br><br>\n",
    "\n",
    "Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken. Additionally, the install the newspaper3k package, which has been tested in this lesson with the version 0.2.8.\n",
    "\n",
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meta claims its new AI supercomputer will set records\n",
      "Text: Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "Meta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\n",
      "\n",
      "The supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
      "\n",
      "RSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\n",
      "\n",
      "“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\n",
      "\n",
      "“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\n",
      "\n",
      "For production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\n",
      "\n",
      "A model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\n",
      "\n",
      "Meta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
      "\n",
      "What this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\n",
      "\n",
      "“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\n",
      "\n",
      "(Image Credit: Meta)\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_url = \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "try:\n",
    "    response = session.get(article_url, headers=headers, timeout=10)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        article = Article(article_url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        \n",
    "        print(f\"Title: {article.title}\")\n",
    "        print(f\"Text: {article.text}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to fetch article at {article_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while fetching article at {article_url}: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code imports essential classes and functions from the LangChain and sets up a ChatOpenAI instance with a temperature of 0 for controlled response generation. Additionally, it imports chat-related message schema classes, which enable the smooth handling of chat-based tasks. The following code will start by setting the prompt and filling it with the article’s content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "# we get the article data from the scraping part\n",
    "article_title = article.title\n",
    "article_text = article.text\n",
    "\n",
    "# prepare template for prompt\n",
    "template = \"\"\"You are a very good assistant that summarizes online articles.\n",
    "\n",
    "Here's the article you want to summarize.\n",
    "\n",
    "==================\n",
    "Title: {article_title}\n",
    "\n",
    "{article_text}\n",
    "==================\n",
    "\n",
    "Write a summary of the previous article.\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(article_title=article.title, article_text=article.text)\n",
    "\n",
    "messages = [HumanMessage(content=prompt)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HumanMessage is a structured data format representing user messages within the chat-based interaction framework. The ChatOpenAI class is utilized to interact with the AI model, while the HumanMessage schema provides a standardized representation of user messages. The template consists of placeholders for the article's title and content, which will be substituted with the actual article_title and article_text. This process simplifies and streamlines the creation of dynamic prompts by allowing you to define a template with placeholders and then replace them with actual data when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# load the model\n",
    "chat = ChatOpenAI(engine=chat_ai, temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we loaded the model and set the temperature to 0. We’d use the chat() instance to generate a summary by passing a single HumanMessage object containing the formatted prompt. The AI model processes this prompt and returns a concise summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta, formerly Facebook, has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world's fastest once fully built in mid-2022. The aim is for it to be capable of training models with trillions of parameters and to be used for tasks such as identifying harmful content on its platforms. Meta expects RSC to be 20 times faster than its current V100-based clusters and estimates it will be nine times faster at running the NVIDIA Collective Communication Library and three times faster at training large-scale natural language processing workflows.\n"
     ]
    }
   ],
   "source": [
    "# generate summary\n",
    "summary = chat(messages)\n",
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Meta, formerly Facebook, has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world's fastest once fully built in mid-2022. The aim is for it to be capable of training models with trillions of parameters and to be used for tasks such as identifying harmful content on its platforms. Meta expects RSC to be 20 times faster than its current V100-based clusters and estimates it will be nine times faster at running the NVIDIA Collective Communication Library and three times faster at training large-scale natural language processing workflows.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Meta has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world's fastest.\n",
      "- The RSC is yet to be fully complete, but Meta's researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
      "- The aim is for the RSC to be capable of training models with trillions of parameters and to be fully built by mid-2022.\n",
      "- Meta hopes that the RSC will help build entirely new AI systems that can power real-time voice translations to large groups of people speaking different languages.\n",
      "- The RSC is expected to be 20x faster than Meta's current V100-based clusters for production and 9x faster at running the NVIDIA Collective Communication Library (NCCL).\n",
      "- Meta's previous AI research infrastructure only leveraged open source and other publicly-available datasets, but the RSC was designed with security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
      "- Meta believes that this is the first time performance, reliability, security, and privacy have been tackled at such a scale.\n"
     ]
    }
   ],
   "source": [
    "# prepare template for prompt\n",
    "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists.\n",
    "\n",
    "Here's the article you need to summarize.\n",
    "\n",
    "==================\n",
    "Title: {article_title}\n",
    "\n",
    "{article_text}\n",
    "==================\n",
    "\n",
    "Now, provide a summarized version of the article in a bulleted list format.\n",
    "\"\"\"\n",
    "\n",
    "# format prompt\n",
    "prompt = template.format(article_title=article.title, article_text=article.text)\n",
    "\n",
    "# generate summary\n",
    "summary = chat([HumanMessage(content=prompt)])\n",
    "print(summary.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get the summary in French, you can instruct the model to generate the summary in French language. However, please note that GPT-4's main training language is English and while it has a multilingual capability, the quality may vary for languages other than English. Here's how you can modify the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Meta a dévoilé un superordinateur d'IA appelé AI Research SuperCluster (RSC)\n",
      "- Le RSC est encore en cours de construction, mais les chercheurs de Meta l'utilisent déjà pour entraîner des modèles de traitement du langage naturel et de vision par ordinateur\n",
      "- Meta affirme que le RSC sera le plus rapide au monde une fois terminé et capable de former des modèles avec des billions de paramètres\n",
      "- Le RSC devrait être 20 fois plus rapide que les clusters actuels de Meta pour la production\n",
      "- Meta prévoit que le RSC sera 9 fois plus rapide pour exécuter la bibliothèque de communication collective NVIDIA (NCCL) et 3 fois plus rapide pour former des flux de travail NLP à grande échelle\n",
      "- Le RSC permettra à Meta de développer de nouvelles applications d'IA pour le metaverse\n",
      "- Meta peut utiliser le RSC pour avancer la recherche sur des tâches vitales telles que l'identification de contenu nuisible sur ses plateformes en utilisant des données réelles\n",
      "- Le RSC a été conçu avec des contrôles de sécurité et de confidentialité pour permettre à Meta d'utiliser des exemples du monde réel de ses systèmes de production dans la formation de production\n",
      "- Meta affirme que c'est la première fois que la performance, la fiabilité, la sécurité et la confidentialité ont été abordées à une telle échelle\n"
     ]
    }
   ],
   "source": [
    "# prepare template for prompt\n",
    "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists in French.\n",
    "\n",
    "Here's the article you need to summarize.\n",
    "\n",
    "==================\n",
    "Title: {article_title}\n",
    "\n",
    "{article_text}\n",
    "==================\n",
    "\n",
    "Now, provide a summarized version of the article in a bulleted list format, in French.\n",
    "\"\"\"\n",
    "\n",
    "# format prompt\n",
    "prompt = template.format(article_title=article.title, article_text=article.text)\n",
    "\n",
    "# generate summary\n",
    "summary = chat([HumanMessage(content=prompt)])\n",
    "print(summary.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution we've presented here is powerful because it leverages the capabilities of LangChain and GPT-4, a state-of-the-art language model developed by OpenAI, to understand and generate human-like text based on natural language instructions. This allows us to interact with the model as we would with a human, asking it to perform complex tasks, like summarizing an article in a bulleted list format in French, with ease and precision.\n",
    "\n",
    "The process under the hood of this code is quite fascinating. First, we obtain the article data, including the title and text. We then prepare a template for the prompt we want to give to the AI model. This prompt is designed to simulate a conversation with the model, telling it that it's an \"advanced AI assistant\" and giving it a specific task - to summarize the article into a bulleted list in French.\n",
    "\n",
    "Once the template is ready, we load the GPT-4 model using ChatOpenAI class with a certain temperature setting, which influences the randomness of the model's outputs. We then format the prompt using the article data.\n",
    "\n",
    "The core part of the process is when we pass the formatted prompt to the model. The model parses the prompt, understands the task, and generates a summary accordingly. It uses its vast knowledge, trained on diverse internet text, to comprehend and summarize the article in French.\n",
    "\n",
    "Lastly, the generated summary, which is a response from the model, is printed. The summary is expected to be a concise, bullet-point version of the article in French, just as we instructed the model in the prompt.\n",
    "\n",
    "In essence, we are guiding the model using natural language instructions to generate the desired output. This interaction is akin to how we might ask a human assistant to perform a task, making it a powerful and intuitive solution for a variety of applications.\n",
    "\n",
    "### Conclusion\n",
    "In conclusion, we've illustrated the process of creating a robust News Articles Summarizer utilizing the capabilities of ChatGPT and LangChain. This potent tool simplifies the task of staying informed by extracting and condensing vital information from a myriad of articles into accessible, AI-generated summaries. The process has been further enriched by converting these summaries into bulleted lists, enhancing readability and comprehension.\n",
    "\n",
    "In response to the requirements of a multilingual audience, we've also expanded the scope of our summarizer to provide summaries in different languages, French being our exemplary case. This showcases the potential of our tool to cater to a diverse, global audience.\n",
    "\n",
    "The crux of this article is the workflow we've outlined - a step-by-step guide that empowers you to construct your own summarizer. With this, you can streamline your information consumption process, save considerable time, and stay abreast with the latest news and developments.\n",
    "\n",
    "We've also delved into the intricacies of prompt construction. A well-crafted prompt ensures that the model understands the task, which in our case, involved summarizing an article into a bulleted list and in a different language. By comprehending the nuances of prompt design, you can further tweak the model to generate outputs that suit your unique needs.\n",
    "\n",
    "In the next lesson, we’ll see more about open-source LLMs and how some of them can be used locally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
