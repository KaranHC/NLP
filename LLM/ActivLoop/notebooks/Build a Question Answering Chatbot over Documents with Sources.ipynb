{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sri.karan\\.conda\\envs\\activeloop\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.18) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import openai,os\n",
    "load_dotenv(r'D:\\Git\\NLP\\LLM\\ActivLoop\\.env')\n",
    "openai_api_key = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "openai.api_base = os.getenv(\"OpenAiService\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =os.getenv(\"OpenAiVersion\")\n",
    "davincimodel= os.getenv(\"OpenAiDavinci\")\n",
    "active_loop_token=os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "embedding_model=os.getenv(\"OpenAiEmbedding\")\n",
    "chat_ai=os.getenv(\"ChatAI\")#\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Let’s explore a more advanced application of Artificial Intelligence - building a Question Answering (QA) Chatbot that works over documents and provides sources of information for its answers. Our QA Chatbot uses a chain (specifically, the RetrievalQAWithSourcesChain), and leverages it to sift through a collection of documents, extracting relevant information to answer queries.\n",
    "\n",
    "The chain sends structured prompts to the underlying language model to generate responses. These prompts are crafted to guide the language model's generation, thereby improving the quality and relevance of the responses. Additionally, the retrieval chain is designed to keep track of the sources of information it retrieves to provide answers, offering the ability to back up its responses with credible references.\n",
    "\n",
    "As we proceed, we'll learn how to:\n",
    "\n",
    "1. Scrape online articles and store each article's text content and URL.\n",
    "2. Use an embedding model to compute embeddings of these documents and store them in Deep Lake, a vector database.\n",
    "3. Split the article texts into smaller chunks, keeping track of each chunk's source.\n",
    "4. Utilize RetrievalQAWithSourcesChain to create a chatbot that retrieves answers and tracks their sources.\n",
    "5. Generate a response to a query using the chain and display the answer along with its sources.\n",
    "\n",
    "\n",
    "This knowledge can be transformative, allowing you to create intelligent chatbots capable of answering questions with sourced information, increasing the trustworthiness and utility of the chatbot.\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "Setup\n",
    "Remember to install the required packages with the following command: pip install langchain==0.0.208 deeplake openai tiktoken. Additionally, install the newspaper3k package with version 0.2.8."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping for the News\n",
    "Now, let's begin by fetching some articles related to AI news. We're particularly interested in the text content of each article and the URL where it was published.\n",
    "\n",
    "In the code, you’ll see the following:\n",
    "\n",
    "1. Imports: We begin by importing necessary Python libraries. requests are used to send HTTP requests, the newspaper is a fantastic tool for extracting and curating articles from a webpage, and time will help us introduce pauses during our web scraping task.\n",
    "2. Headers: Some websites may block requests without a proper User-Agent header as they may consider it as a bot's action. Here we define a User-Agent string to mimic a real browser's request.\n",
    "3. Article URLs: We have a list of URLs for online articles related to artificial intelligence news that we wish to scrape.\n",
    "4. Web Scraping: We create an HTTP session using requests.Session() allows us to make multiple requests within the same session. We also define an empty list of pages_content to store our scraped articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/',\n",
       "  'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nOpenAI CEO Sam Altman testified in front of a Senate judiciary committee panel and emphasised the importance of regulating AI.\\n\\nAltman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models.\\n\\nAltman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial.\\n\\nSenators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\\n\\nBlumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\\n\\nAltman’s call for regulation aligns with concerns raised by AI experts and ethicists, including former Google researchers Dr Timnit Gebru and Meredith Whitaker. They argue that the rapid adoption of AI is overhyped and fails to deliver inherent social good.\\n\\nWhitaker highlighted the concentration of power in the hands of a few tech companies and their ability to shape social and political landscapes through AI technologies. She expressed concerns about the existing power dynamics and emphasised the need for a more equitable distribution of AI capabilities.\\n\\nWhitaker cautioned against the notion that AI will automatically lead to social good or equal access for all, arguing that it is a fantasy propagated for marketing purposes. She stressed the importance of acknowledging the concentration of power and the need to ensure that AI is harnessed for the benefit of society as a whole.\\n\\nAs AI continues to advance, the conversation surrounding its regulation and responsible deployment becomes increasingly important. Balancing the potential benefits with the risks and ensuring equitable access and distribution of AI technologies are key challenges that policymakers, researchers, and industry leaders must address collectively.\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\"},\n",
       " {'url': 'https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/',\n",
       "  'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nIBM has been refining its AI solutions for decades and knows a thing or two about helping businesses leverage the technology to improve productivity.\\n\\nIn 1997, IBM’s Deep Blue supercomputer was used to beat World Chess Champion Garry Kasparov. At the time, all too familiar headlines suggested that computers would soon replace humans. Over two decades later, AI has proven to be an assistive tool that benefits us every day.\\n\\nIBM Watson’s first commercial application was announced a little over a decade ago in February 2013 for utilisation management decisions in lung cancer treatment. In the years since, we’ve seen it used to deliver game-changing advancements in healthcare, weather forecasting, education, science, and much more.\\n\\nAI News caught up with Jay Migliaccio, Senior Product Manager for Watson Orchestrate, to learn how IBM is now using its vast experience to help businesses with their digital transformations.\\n\\nAI News: So, Jay, can you tell me how IBM is helping businesses to improve the productivity of their workforces?\\n\\nJay Migliaccio: Yes, Ryan. Thanks so much for the invite and for asking me here.\\n\\nIBM is expanding its suite of offerings in the area of digital labour. Digital labour leverages AI and automation to help workers become more productive. And, much like human labour, digital labour performs work on business systems through “skills”.\\n\\nDigital labour skills enable digital labour to interact with business applications, much like you and I would interact with a system of record or system of engagement. We can do this now through digital labour. And, what’s new and unique, is that digital labour leverages the human-centric interaction style.\\n\\nSo, we’ve introduced natural language and we’ve also introduced intelligent orchestration to be able to execute not just single skills, but actually multiple skills to be able to achieve higher-level tasks.\\n\\nAN: Generative AI is a hot topic in the market at the moment. Do you see that being used practically in the workplace and what risks should businesses be aware of?\\n\\nJM: Yeah, great question. I actually do use it myself in the workplace, I occasionally have to develop software tools and simple scripts and I have had it generate a number of scripts for me successfully. So I’m impressed not just with its ability to generate verbal and written content, but also code content. I for sure believe it will become increasingly useful in the workplace.\\n\\nCurrent generative AI platforms have been trained on the internet, so remember your results may vary. I know anytime I Google or search for things on the internet I take the results with a grain of salt.\\n\\nI believe that enterprises, as they go to look and adopt generative AI systems, they’ll lean more towards AI that they can trust. Therefore, we need to work on being able to create that trust element in generative AI solutions.\\n\\nAN: What is the value of Watson Orchestrate for developers?\\n\\nJM: When we talk about developers, I’m talking about automation developers. And that’s by and large developers that are integrating apps and business apps and business systems to work together.\\n\\nFor the most part, those developers have been integrating business systems to business systems. Now what we can do with Watson Orchestrate is we can introduce the human into the loop.\\n\\nThese automation developers now have a platform where they can build and integrate their automation workflows and they can bring a human experience into these automation workflows for everyday human workers.\\n\\nWatson Orchestrate provides a platform for creating human-centric workflow automation, designed to interact with humans in our native communication style which is spoken or written word.\\n\\nAN: How does Watson Orchestrate learn from user interactions?\\n\\nJM: There are a couple of ways Watson Orchestrate is monitoring the behaviour of humans and learning from them.\\n\\nPerhaps most important is its ability to interpret the natural language through which humans are communicating. Today it’s the written word, but in the future spoken word. Watson Orchestrate can not just do a pattern match based on existing known sentences, but it can actually understand the intent of those utterances.\\n\\nAdditionally, it can extract entities from those utterances. So, when you use proper nouns in a sentence, it can understand that’s an entity that it would use as part of an automation. It can match the intent of the utterance to existing skills that it has and can react accordingly. It can understand the intent of the utterance and then take action on those skills. Increasingly, it can sequence multiple skills together.\\n\\nAlso, we are working on systems for empowering Watson Orchestrate to monitor the user’s behaviour. And, just like any modern SaaS application today that has recommendations based on your behaviour, we’re working on recommendation engines to recommend to employees how they can use Watson Orchestrate to be more productive in the future.\\n\\nAN: Talking about AI more generally, what new ways of working are today’s advancements enabling?\\n\\nJM: As I just alluded to, we’re increasingly empowering systems to understand human natural language to a much more complex and sophisticated extent. Natural language interpretation has grown way beyond the basic pre-programmed bot experience.\\n\\nI’m sure everybody has had an experience on a website where there’s a bot responding to your basic questions. What we’re trying to do is make that bot much more intelligent. The current generation of digital labour can understand your intent, extract entities from your utterances, and, most importantly, take action on your behalf.\\n\\nAN: On the flip side, what are some of the main dangers of automation tools and how do we overcome those?\\n\\nJM: I’m not sure if this is a specific category of danger, but I suppose I would put it under the law of unintended consequences. Anytime you work with technology, there can be outcomes that you don’t expect.\\n\\nFor example, if we think about the automobile as an automation tool for moving humans around – the intent, of course, was to move a human from A to B faster, and maybe more reliably. But the net result is occasionally we have accidents.\\n\\nMuch like the way we build transportation systems to constrain and reduce the potential for accidents, we have to do the same thing in our business systems with digital labour. Certainly, we’re going to want to start small and just do very selective, very specific tasks that are well-curated and well-defined.\\n\\nWe’ll need to create guardrails that guard against unintended and unexpected behaviour. One of the ways we’re doing this in Watson Orchestrate is to empower the digital labour to act on the user’s behalf and therefore leverage the user’s credentials when interacting with business systems.\\n\\nAs an employee, I’m given certain access to a business system based on my role. Therefore, we know when the digital employee performs actions on my behalf it also has those existing restrictions and permissions for those business systems.\\n\\nAnother option is monitoring behaviour and monitoring for unintended consequences. And, lastly, integrating governance and creating policies that permit or restrict the behaviour of digital employees.\\n\\nAN: Are you a believer in the metaverse? If so, how much work do you think we will be doing in it?\\n\\nJM: Yeah, great question. Metaverse for me is a very loose term. Here we are digitally speaking – we’ve never met before, you could be an avatar for all I know. So, in that sense, I’m a believer in the metaverse.\\n\\nFor me, like most innovative technologies, it will start on the fringe and work its way into the mainstream. You can look at entertainment and gaming and see very metaverse-like experiences being used there.\\n\\nI’ve seen examples of the metaverse being used for deep meditative experiences. If you want to go into deep meditation, you can put on your virtual headsets and enter a metaverse world that is very different from the physical world we live in.\\n\\nAnd I also can see the metaverse being initially used for education purposes. I think it’s a great way – a sort of low-risk way – to introduce people to new environments and new ideas at scale.\\n\\nI don’t think we’re gonna go to the metaverse to go to work. I don’t see that as something coming in the near term.\\n\\nAN: I can only promise I’m not an avatar for the time being. I might bump into you at Digital Transformation Week, next week. You’ll obviously be in attendance, what will you be sharing with the audience at the event?\\n\\nJM: Yeah, Digital Transformation Week I will be talking about our view on the digital labour market and some of our solutions. I will also be sharing some of the stories about the early adopters of IBM’s digital labour solutions.\\n\\nYou can watch our full interview with Jay below:\\n\\nIBM is a headline sponsor of Digital Transformation Week on 17-18 May 2023 and will be sharing its expertise with attendees. Swing by IBM’s booth at stand #236 and check out Jay Migliaccio’s keynote at 10:30am on day one.\"},\n",
       " {'url': 'https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/',\n",
       "  'text': 'Duncan is an award-winning editor with more than 20 years experience in journalism. Having launched his tech journalism career as editor of Arabian Computer News in Dubai, he has since edited an array of tech and digital marketing publications, including Computer Business Review, TechWeekEurope, Figaro Digital, Digit and Marketing Gazette.\\n\\nCould you tell us a little bit about SoftServe and what the company does?\\n\\nSure. We’re a 30-year-old global IT services and professional services provider. We specialise in using emerging state-of-the-art technologies, such as artificial intelligence, big data and blockchain, to solve real business problems. We’re highly obsessed with our customers, about their problems – not about technologies – although we are technology experts. But we always try to find the best technology that will help our customers get to the point where they want to be.\\n\\nSo we’ve been in the market for quite a while, having originated in Ukraine. But now we have offices all over the globe – US, Latin America, Singapore, Middle East, all over Europe – and we operate in multiple industries. We have some specialised leadership around specific industries, such as retail, financial services, healthcare, energy, oil and gas, and manufacturing. We also work with a lot of digital natives and independent software vendors, helping them adopt this technology in their products, so that they can better serve their customers.\\n\\nWhat are the main trends you’ve noticed developing in AI and machine learning?\\n\\nOne of the biggest trends is that, while people used to question whether AI, machine learning and data science are the technologies of the future; that’s no longer the question. This technology is already everywhere. And the vast majority of the innovation that we see right now wouldn’t have been possible without these technologies.\\n\\nOne of the main reasons is that this tech allows us to address and solve some of the problems that we used to consider intractable. Think of natural language, image recognition or code generation, which are not only hard to solve, they’re also hard to define. And approaching these types of problems with our traditional engineering mindset – where we essentially use programming languages – is just impossible. Instead, we leverage the knowledge stored in the vast amounts of data we collect, and use it to find solutions to the problems we care about. This approach is now called Machine Learning, and it is the most efficient way to address those types of problems nowadays.\\n\\nBut with the amount of data we can now collect, the compute power available in the cloud, the efficiency of training and the algorithms that we’ve developed, we are able to get to the stage where we can get superhuman performance with many tasks that we used to think only humans could perform. We must admit that human intelligence is limited in capacity and ability to process information. And machines can augment our intelligence and help us more efficiently solve problems that our brains were not designed for.\\n\\nThe overall trend that we see now is that machine learning and AI are essentially becoming the industry standard for solving complex problems that require knowledge, computation, perception, reasoning and decision-making. And we see that in many industries, including healthcare, finance and retail.\\n\\nThere are some more specific emerging trends. The topic of my TechEx North America keynote will be about generative AI, which many folk might think is something just recently invented, something new, or they may think of it as just ChatGPT. But these technologies have been evolving for a while. And we, as hands-on practitioners in the industry, have been working with this technology for quite a while.\\n\\nWhat has changed now is that, based on the knowledge and experience we’ve collected, we were able to get this tech to a stage where GenAI models are useful. We can use it to solve some real problems across different industries, from concise document summaries to advanced user experiences, logical reasoning and even the generation of unique knowledge. That said, there are still some challenges with reliability, and understanding the actual potential of these technologies.\\n\\nHow important are AI and machine learning with regards to product innovation?\\n\\nAI and Machine Learning essentially allow us to address the set of problems that we can’t solve with traditional technology. If you want to innovate, if you want to get the most out of tech, you have to use them. There’s no other choice. It’s a powerful tool for product development, to introduce new features, for improving customer user experiences, for deriving some really deep actionable insights from the data.\\n\\nBut, at the same time, it’s quite complex technology. There’s quite a lot of expertise involved in applying this tech, training these types of models, evaluating them, deciding what model architecture to use, etc. And, moreover, they’re highly experiment driven, meaning that in traditional software development we often know in advance what to achieve. So we set some specific requirements, and then we write a source code to meet those requirements.\\n\\nAnd that’s primarily because, in traditional engineering, it’s the source code that defines the behaviour of our system. With machine learning and artificial intelligence the behaviour is defined by the data, which means that we hardly ever know in advance what the quality of our data is. What’s the predictive power of our data? What kind of data do we need to use? Whether the data that we collected is enough, or whether we need to collect more data. That’s why we always need to experiment first.\\n\\nBut I think, in some way, we got used to the uncertainty in the process and the outcomes of AI initiatives. The AI industry gave up on the idea that machine learning will be predictable at some point. Instead, we learned how to experiment efficiently, turning our ideas into hypotheses that we can quickly validate via experimentation and rapid prototyping, and evolving the most successful experiments into full-fledged products. That’s essentially what the modern lifecycle of AI/ML products looks like.\\n\\nIt also requires the product teams to adopt a different mindset of constant ideation and experimentation, though. It starts with selecting those ideas and use cases that have the highest potential, the most feasible ones that may have the biggest impact on the business and the product. From there, the team can ideate around potential solutions, quickly prototyping and selecting those that are most successful. That requires experience in identifying the problems that can benefit from AI/ML the most, and agile, iterative processes of validating and scaling the ideas.\\n\\nHow can businesses use that type of technology to improve personalisation?\\n\\nThat’s a good question because, again, there are some problems that are really hard to define. Personalisation is one of them. What makes me or you a person? What contributes to that? Whether it’s our preferences. How do we define our preferences? They might be stochastic, they might be contextual. It’s a highly multi dimensional problem.\\n\\nAnd, although you can try to approach it with a more traditional tech, you’ll still be limited in that capacity – depths of personalisation that you may get. The most efficient way is to learn those personal signals, preferences from the data, and use those insights to deliver personalised experiences, personalised marketing, and so on.\\n\\nEssentially, AI/ML acts as a sort of black box between the signal and the user and specific preferences, specific content that would resonate with that specific user. As of right now, that’s the most efficient way to achieve personalisation.\\n\\nOne other benefit of modern AI/ML is that you can use various different types of data. You can combine clickstream data from your website, collecting information about how users behave on your website. You can collect text data from Twitter or any other sources. You can collect imagery data, and you can use all that information to derive the insights you care about. So the ability to analyse that heterogeneous set of data is another benefit that AI/ML brings into this game.\\n\\nHow do you think machine learning is impacting the metaverse and how are businesses benefiting from that?\\n\\nThere are two different aspects. ‘Metaverse’ is quite an abstract term, and we used to think of it from two different perspectives. One of them is that you want to replicate your physical assets – part of our physical world in the metaverse. And, of course, you can try to approach it from a traditional engineering standpoint, but many of the processes that we have are just too complex. It’s really hard to replicate them in a digital world. So think of a modern production line in manufacturing. In order for you to have a really precise, let’s call it a digital twin, of some physical assets, you have to be smart and use something that will allow you to get as close as possible in your metaverse to the physical world. And AI/ML is the way to go. It’s one of the most efficient ways to achieve that.\\n\\nAnother aspect of the metaverse is that since it’s digital, it’s unlimited. Thus, we may also want to have some specific types of assets that are purely digital, that don’t have any representation in the real world. And those assets should have similar qualities and behaviour as the real ones, handling a similar level of complexity. In order to program these smart, purely digital processes or assets, you need AI and ML to make them really intelligent.\\n\\nAre there any examples of companies that you think have been utlising AI and machine learning well?\\n\\nThere are the three giants – Facebook, Google, Amazon. All of them are essentially a key driver behind the industry. And the vast majority of their products are, in some way, powered by AI/ML. Quite a lot has changed since I started my career but, even when I joined SoftServe around 10 years ago, there was a lot of research going on into AI/ML.\\n\\nThere were some big players using the technology, but the vast majority of the market were just exploring this space. Most of our customers didn’t know anything about it. Some of the first questions they had were ‘can you educate us on this? What is AI/ML? How can we use it?’\\n\\nWhat has changed now is that almost any company we interact with has already done some AI/ML work, whether they build something internally or they use some AI/ML products. So the perception has changed.\\n\\nThe overall adoption of this technology now is at the scale where you can find some aspects of AI/ML in almost any company.\\n\\nYou may see a company that does a lot of AI/ML on their, let’s say, marketing or distribution, but they have some old school legacy technologies in their production site or in their supply chain. The level of AI/ML adoption may differ across different lines of business. But I think almost everyone is using it now. Even your phone, it’s backed with AI/ML features. So it’s hard to think of a company that doesn’t use any AI/ML right now.\\n\\nDo you think, in general, companies are using AI and machine learning well? What kind of challenges do they have when they implement it?\\n\\nThat’s a good question. The main challenge of applying these technologies today is not how to be successful with this tech, but rather how to be efficient. With the amount of data that we have now, and data that the companies are collecting, plus the amount of tech that is open source or publicly available – or available as managed services from AWS, from GCP – it’s easy to get some good results.\\n\\nThe question is, how do you decide where to apply this technology? How efficiently can you identify those opportunities, and find the ones that will bring the biggest impact, and can be implemented in the most time-efficient and cost-effective manner?\\n\\nAnother aspect is how do you quickly turn those ideas into production-grade products? It’s a highly experiment-driven area, and there is a lot of science, but you still need to build reliable software on the research results.\\n\\nThe key drivers for successful AI adoption are finding the right use cases where you can actually get the desired outcomes in the most efficient way, and turn ideas into full-fledged products. We’ve seen some really innovative companies that had brilliant ideas. They may have built some proof of concepts around their ideas, but they didn’t know how to evolve or how to build reliable products out of it. At the same time, there are some technically savvy and digitally native companies. They have tonnes of smart engineers, but they don’t have the right expertise and experience in AI/ML technologies. They don’t know how to apply this tech to real business problems, or what low-hanging fruits are available to them. They just struggle with finding the best way to leverage this tech.\\n\\nWhat do you think the future holds for AI and machine learning?\\n\\nI generally try to be more optimistic about the future because there are obviously a lot of fears around AI/ML. And I think that’s quite natural. If you look back in history, it was the same with electricity and any other innovative technologies.\\n\\nOne of the fears that I think does have some merit is that this technology may replace some real jobs. I think that’s a bit of a pessimistic view because history also teaches us that whatever technology we get, we still need that human aspect to it.\\n\\nAlmost all the technology that we use right now augments our intelligence. It does not replace it. And I think that the future of AI will be used in a cooperative way. If you’ve seen products like GitHub Copilot, the purpose of this product is essentially to assist the developer in writing code. We still can’t use AI to write entire programs. We need a human to guide that AI to our desired outcome. What exactly do we want to achieve? What is our objective? What is our user expectation?\\n\\nSimilarly, maybe this technology will be applied to a broader set of use cases where AI will be assisting us, not replacing us. There is a quote that I wish was mine but I still think it’s a very good way of thinking about the role of AI: if you think that AI will replace you or your job, most likely you’re wrong. It’s the people who will be using AI who will replace you at your job.\\n\\nSo I think one of the most important skills to learn right now is how to leverage this tech to make your work more efficient. And that should help many people get that competitive advantage in the future.\\n\\nIurii Milovanov is the director of AI and data science at SoftServe, a technology company specialising in consultancy services and software development.\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.'},\n",
       " {'url': 'https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/',\n",
       "  'text': 'The AI and Big Data Expo North is taking place in Santa Clara, between 17-18 May, and there’s now less than one week left to register your tickets to join the world-leading event.\\n\\nOver 6,000 attendees are expected to attend the expo from across the globe, including IT decision makers, developers & designers, heads of innovation, chief data officers, chief data scientists, brand managers, data analysts, start-ups and innovators, tech providers, c-level executives, venture capitalists, and many more.\\n\\n“We are thrilled to welcome so many industry experts and enthusiasts to our event,” said Olivia Reid, Head of Operations of AI and Big Data Expo. “Our team has worked tirelessly to put together an exciting and informative event that we believe will inspire and educate attendees.”\\n\\nThe AI & Big Data Expo will showcase the most cutting-edge technologies from 250+ speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.\\n\\nThe speaker line-up and agenda have been finalised, with speakers from the likes of Google, Ford, AWS, LinkedIn, eBay, Visa, Nasa, Wells Fargo, Johnson & Johnson and many more leading companies!\\n\\nThe event’s official networking party will take place at the prestigious Levi’s 501 Club at Levi’s Stadium, the home of the San Francisco 49ers! The networking party will allow ‘Gold’ and ‘Ultimate’ pass holders to share the experiences of the day and will provide the opportunity to meet with existing and new business partners in a more relaxed setting, with free food and drinks provided.\\n\\nDon’t miss the opportunity to explore this innovative technology and its impact on a range of industries including, manufacturing, transport, supply chain, government, legal sectors and financial services energy, utilities, insurance, healthcare, retail, and more!'},\n",
       " {'url': 'https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/',\n",
       "  'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nGeoffrey Hinton, known as the “Godfather of AI,” has expressed concerns about the potential dangers of AI and left his position at Google to discuss them openly.\\n\\nHinton, alongside two others, won the Turing Award in 2018 for laying the foundations of AI. He had been working at Google since 2013 but resigned to speak out about the fast pace of AI development and the risks it poses.\\n\\nIn an interview with The New York Times, Hinton warned that the rapid development of generative AI products was “racing towards danger” and that false text, images, and videos created by AI could lead to a situation where average people “would not be able to know what is true anymore.”\\n\\nHinton also expressed concerns about the impact of AI on the job market, as machines could eventually replace roles such as paralegals, personal assistants, and translators.\\n\\n“The idea that this stuff could actually get smarter than people — a few people believed that. But most people thought it was way off. And I thought it was way off. I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that,” said Hinton.\\n\\nHinton’s concerns are not unfounded. AI has already been used to create deepfakes, which are videos that manipulate facial and voice expressions to make it appear that someone is saying something they did not say. These deepfakes can be used to spread misinformation or damage a person’s reputation.\\n\\nFurthermore, AI has the potential to automate many jobs, leading to job losses. This week, IBM CEO Arvind Krishna said that the company plans to use AI to replace around 30 percent of back office jobs—equivalent to around 7,800 jobs.\\n\\nHinton is not alone in his concerns. Other experts have also warned about the risks of AI.\\n\\nElon Musk, the CEO of Tesla and SpaceX, called AI “our biggest existential threat”. The following year, the legendary astrophysicist Neil deGrasse Tyson said that he shares Musk’s view. In 2018, Stephen Hawking warned that AI could replace humans as the dominant species on Earth.\\n\\nIn March, Musk joined Apple co-founder Steve Wozniak and over 1,000 other experts in signing an open letter calling for a halt to “out-of-control” AI development.\\n\\nHowever, some experts believe that AI can be developed in a way that benefits society. For example, AI can be used to diagnose diseases, detect fraud, and reduce traffic accidents.\\n\\nTo ensure that AI is developed in a responsible and ethical manner, many organisations have developed guidelines, including the IEEE, the EU, and the OECD.\\n\\nThe concerns raised by Hinton about AI are significant and highlight the need for responsible AI development. While AI has the potential to bring many benefits to society, it is crucial that it is developed in a way that minimises its risks and maximises its benefits.\\n\\n(Image Credit: Eviatar Bach under CC BY-SA 3.0 license. Image cropped from original.)\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\"},\n",
       " {'url': 'https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/',\n",
       "  'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nPalantir has demonstrated how AI can be used for national defense and other military purposes.\\n\\nThe use of AI in the military is highly controversial. In this context, Large Language Models (LLMs) and algorithms must be implemented as ethically as possible.\\n\\nPalantir believes that’s where its AI Platform (AIP) comes in. AIP offers cutting-edge AI capabilities and claims to ensure that the use of LLMs and AI in the military context is guided by ethical principles.\\n\\nAIP is able to deploy LLMs and AI across any network, from classified networks to devices on the tactical edge. AIP connects highly sensitive and classified intelligence data to create a real-time representation of the environment.\\n\\nThe solution’s security features let you define what LLMs and AI can and cannot see and what they can and cannot do with safe AI and handoff functions. This control and governance are crucial for mitigating significant legal, regulatory, and ethical risks posed by LLMs and AI in sensitive and classified settings.\\n\\nAIP also implements guardrails to control, govern, and increase trust. As operators and AI take action on the platform, AIP generates a secure digital record of operations. These capabilities are essential for responsible, effective, and compliant deployment of AI in the military.\\n\\nIn a demo showcasing AIP, a military operator responsible for monitoring activity within Eastern Europe receives an alert that military equipment is amassed in a field 30km from friendly forces.\\n\\nAIP leverages large language models to allow operators to quickly ask questions such as:\\n\\nWhat enemy units are in the region?\\n\\nTask new imagery for this location at a resolution of one metre or higher\\n\\nGenerate three courses of action to target this enemy equipment\\n\\nAnalyse the battlefield, considering a Stryker vehicle and a platoon-size unit\\n\\nHow many Javelin missiles does Team Omega have?\\n\\nAssign jammers to each of the validated high-priority communications targets\\n\\nSummarise the operational plan\\n\\nAs the operator poses questions, the LLM is using real-time information integrated from across public and classified sources. Data is automatically tagged and protected by classification markings, and AIP enforces which parts of the organisation the LLM has access to while respecting an individual’s permissions, role, and need to know.\\n\\nEvery response from AIP retains links back to the underlying data records to enable transparency for the user who can investigate as necessary.\\n\\nAIP unleashes the power of large language models and cutting-edge AI for defense and military organisations while aiming to do so with the appropriate guardrails and high levels of ethics and transparency that are required for such sensitive applications.\\n\\n\\ufeff\\n\\n(Image Credit: Palantir)\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compute the embeddings of our documents using an embedding model and store them in Deep Lake, a multimodal vector database. OpenAIEmbeddings will be used to generate vector representations of our documents. These embeddings are high-dimensional vectors that capture the semantic content of the documents. When we create an instance of the Deep Lake class, we provide a path that starts with hub://... that specifies the database name, which will be stored on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"hayagriva99999\"\n",
    "my_activeloop_dataset_name = \"langchain_course_qabot_with_source\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a crucial part of the setup because it prepares the system for storing and retrieving the documents based on their semantic content. This functionality is key for the following steps, where we’d find the most relevant documents to answer a user's question.\n",
    "\n",
    "Then, we'll break down these articles into smaller chunks, and for each chunk, we'll save its corresponding URL as a source. This division helps in efficiently processing the data, making the retrieval task more manageable, and focusing on the most relevant pieces of text when answering a question.\n",
    "\n",
    "RecursiveCharacterTextSplitter is created with a chunk size of 1000, and 100 characters overlap between chunks. The chunk_size parameter defines the length of each text chunk, while chunk_overlap sets the number of characters that adjacent chunks will share. For each document in pages_content, the text will be split into chunks using the .split_text() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
    "# we need to use the \"source\" key for the document source so that we can then use the\n",
    "# RetrievalQAWithSourcesChain class which will automatically retrieve the \"source\" item\n",
    "# from the metadata dictionary.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts, all_metadatas = [], []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)\n",
    "        all_metadatas.append({ \"source\": d[\"url\"] })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"source\" key is used in the metadata dictionary to align with the RetrievalQAWithSourcesChain class's expectations, which will automatically retrieve this \"source\" item from the metadata. We then add these chunks to our Deep Lake database along with their respective metadata."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the fun part - building the QA Chatbot. We'll create a RetrievalQAWithSourcesChain chain that not only retrieves relevant document snippets to answer the questions but also keeps track of the sources of these documents.\n",
    "\n",
    "### Setting up the Chain \n",
    "We then create an instance of RetrievalQAWithSourcesChain using the from_chain_type method. This method takes the following parameters:\n",
    "\n",
    "LLM: This argument expects to receive an instance of a model (GPT-3, in this case) with a temperature of 0. The temperature controls the randomness of the model's outputs - a higher temperature results in more randomness, while a lower temperature makes the outputs more deterministic.\n",
    "chain_type=\"stuff\": This defines the type of chain being used, which influences how the model processes the retrieved documents and generates responses. \n",
    "retriever=db.as_retriever(): This sets up the retriever that will fetch the relevant documents from the Deep Lake database. Here, the Deep Lake database instance db is converted into a retriever using its as_retriever method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a RetrievalQAWithSourcesChain chain, which is very similar to a\n",
    "# standard retrieval QA chain but it also keeps track of the sources of the\n",
    "# retrieved documents\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=db.as_retriever())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll generate a response to a question using the chain. The response includes the answer and its corresponding sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a response to a query using the chain. The response object is a dictionary containing\n",
    "# an \"answer\" field with the textual answer to the query, and a \"sources\" field containing a string made\n",
    "# of the concatenation of the metadata[\"source\"] strings of the retrieved documents.\n",
    "d_response = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})\n",
    "\n",
    "print(\"Response:\")\n",
    "print(d_response[\"answer\"])\n",
    "print(\"Sources:\")\n",
    "for source in d_response[\"sources\"].split(\", \"):\n",
    "    print(\"- \" + source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response:\n",
    "\n",
    "\n",
    " Geoffrey Hinton has expressed concerns about the potential dangers of AI, such as false text, images, and videos created by AI, and the impact of AI on the job market. He believes that AI has the potential to replace humans as the dominant species on Earth.\n",
    "\n",
    "Sources:\n",
    "- https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n",
    "- https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You've now built a question-answering chatbot that can provide answers from a collection of documents and indicate where it got its information.\n",
    "\n",
    "### Conclusion\n",
    "The chatbot was able to provide an answer to the question, giving a brief overview of Geoffrey Hinton's views on recent trends in AI. The sources provided and the answer traces back to the original articles expressing these views. This process adds a layer of credibility and traceability to the chatbot's responses. The presence of multiple sources also suggests that the chatbot was able to draw information from various documents to provide a comprehensive answer, demonstrating the effectiveness of the RetrievalQAWithSourcesChain in retrieving information.\n",
    "\n",
    "In the next lesson we’ll build a chatbot that can answer questions over financial documents, such as financial reports PDFs.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/modules/chains/popular/vector_db_qa<br>\n",
    "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/deeplake<br>\n",
    "https://docs.activeloop.ai/quickstart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
